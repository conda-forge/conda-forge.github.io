"use strict";(self.webpackChunkcf_infra_docs=self.webpackChunkcf_infra_docs||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2023/07/13/installer-security-fixes","metadata":{"permalink":"/blog/2023/07/13/installer-security-fixes","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2023-07-13-installer-security-fixes.md","source":"@site/blog/2023-07-13-installer-security-fixes.md","title":"Security updates to our installers","description":"In June 2023, software engineers from","date":"2023-07-13T00:00:00.000Z","formattedDate":"July 13, 2023","tags":[{"label":"security","permalink":"/blog/tags/security"}],"readingTime":1.18,"hasTruncateMarker":true,"authors":[{"name":"conda-forge/core","title":"The conda-forge core team","url":"https://github.com/orgs/conda-forge/teams/core","imageURL":"https://github.com/conda-forge.png","key":"core"}],"frontMatter":{"authors":["core"],"tags":["security"]},"unlisted":false,"nextItem":{"title":"CircleCI Security Incident","permalink":"/blog/2023/03/12/circle-ci-security-breach"}},"content":"In June 2023, software engineers from\\n[Anaconda](https://www.anaconda.com) have reported a security issue in\\nthe uninstallers that are included in the Windows versions of the\\n[miniforge and mambaforge\\ninstallers](https://github.com/conda-forge/miniforge), one of the main\\nways to bootstrap conda-forge based conda and mamba distributions.\\n\\n\x3c!--truncate --\x3e\\n\\nThe issue could, under specific conditions, unintentionally delete files\\nfrom your system during the uninstallation process. Anaconda has\\npublished more details in the related\\n[blogpost](https://www.anaconda.com/blog/windows-installer-security-fix)\\nabout the security fix for the miniconda and Anaconda Distribution\\nWindows installers as well.\\n\\nconda-forge is committed to fix the miniforge and mambaforge installers\\nequally to reduce the possible impact on conda-forge users and has\\nworked with Anaconda to mitigate the issue.\\n\\n- As such, we are strongly recommending all users of miniforge and\\n  mambaforge to **update immediately** to the latest versions of\\n  miniforge and mambaforge. Please download them from the [miniforge\\n  repository\'s main page](https://github.com/conda-forge/miniforge)\\n  or the [release specific\\n  page](https://github.com/conda-forge/miniforge/releases/tag/23.1.0-4).\\n- For older versions, we are providing a **security patch for already\\n  installed miniforge and mambaforge installations**. You can download\\n  these from [release specific\\n  page](https://github.com/conda-forge/miniforge/releases/tag/23.1.0-4)\\n  as well, under the names\\n  `Miniforge3-uninstaller-patch-Windows-x86_64.exe` and\\n  `Mambaforge-uninstaller-patch-Windows-x86_64.exe`.\\n\\n:::note\\nTo uninstall older versions of miniforge and mambaforge released before\\nJuly 1, 2023, please download the security patch fix prior to\\nuninstallation.\\n:::\\n\\nIn order for this flaw to be triggered, a specific combination of\\nfactors must align, including uninstallation permissions, system access,\\nusage of Windows, and an existing installation of miniforge or\\nmambaforge."},{"id":"/2023/03/12/circle-ci-security-breach","metadata":{"permalink":"/blog/2023/03/12/circle-ci-security-breach","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2023-03-12-circle-ci-security-breach.md","source":"@site/blog/2023-03-12-circle-ci-security-breach.md","title":"CircleCI Security Incident","description":"In early January 2023, CircleCI informed us that they had a large","date":"2023-03-12T00:00:00.000Z","formattedDate":"March 12, 2023","tags":[{"label":"security","permalink":"/blog/tags/security"}],"readingTime":4.045,"hasTruncateMarker":true,"authors":[{"name":"conda-forge/core","title":"The conda-forge core team","url":"https://github.com/orgs/conda-forge/teams/core","imageURL":"https://github.com/conda-forge.png","key":"core"}],"frontMatter":{"authors":["core"],"tags":["security"]},"unlisted":false,"prevItem":{"title":"Security updates to our installers","permalink":"/blog/2023/07/13/installer-security-fixes"},"nextItem":{"title":"Outreachy 2022 Wrap-up Blog","permalink":"/blog/2022/08/26/outreachy-wrap-up-blog-2022"}},"content":"In early January 2023, CircleCI informed us that they had a large\\n[security breach](https://circleci.com/blog/jan-4-2023-incident-report/)\\nwhere a third party had gained access to all the environment secrets\\nstored in the service. For `conda-forge`, these secrets are the API\\ntoken used to upload built packages to our staging area on\\n`anaconda.org` and the unique token we generate for each feedstock. The\\nfeedstock tokens are used as part of our artifact staging process to\\nensure that only the maintainers of a given feedstock can upload\\npackages built by that feedstock. Later in January, we were informed by\\nCircleCI that their security breach started on December 19, 2022, with\\nthe bulk of the secrets being exfiltrated in plain text from their\\nservers a few days later. A malicious third-party with access to these\\nsecrets could potentially upload compromised versions of any package on\\n`conda-forge` in a so-called \\"supply chain\\" attack.\\n\\n\x3c!--truncate --\x3e\\n\\n**We have produced a** [list of all possibly compromised\\nartifacts](https://raw.githubusercontent.com/conda-forge/conda-forge.github.io/main/misc/circle_ci_pkgs_dec2022_breach.json).\\n\\n**If you use** `conda-forge` **in very sensitive environments (which we\\ndo not recommend!), please remove these artifacts from your system.**\\n\\n**To date, we know of no compromised artifacts in** `conda-forge`.\\n\\n**API tokens for the main** `conda-forge` **channel were never exposed\\nand remain secure to our knowledge.**\\n\\n## Our Response\\n\\nWe took the following steps to respond to this incident.\\n\\n- We immediately started a token rotation of all of our feedstock\\n  tokens and our staging area upload tokens as precautionary measures.\\n  This token rotation hit a few bugs, but was completed as of January\\n  13, 2023.\\n- We produced a census of all packages uploaded between December 19,\\n  2022 and January 13, 2023. This data is available for download as a\\n  [JSON\\n  file](https://raw.githubusercontent.com/conda-forge/conda-forge.github.io/main/misc/circle_ci_pkgs_dec2022_breach.json).\\n- We examined all the artifacts built during this time period for the\\n  [malicious\\n  files](https://circleci.com/blog/jan-4-2023-incident-report/) listed\\n  by CicleCI. We did not find any of those files in our artifacts.\\n- As detailed below, we have begun retooling our system for feedstock\\n  tokens to be more robust and enable greater flexibility in our\\n  response to incidents like this.\\n- We have begun systematically invalidating old tokens,\\n  decommissioning old bots, and minimizing permissions of our current\\n  tokens in order to further enhance `conda-forge`\'s security.\\n\\nRotating all of our tokens was taken as a precautionary measure.\\nUnfortunately, during this token rotation, one of our bots encountered a\\nbug which resulted in us losing the tokens for a very large fraction of\\nfeedstocks. This situation resulted in an extended outage that lasted\\nabout five days and was resolved on January 13, 2023, when the full\\ntoken rotation was completed.\\n\\n## What did we learn?\\n\\nWe learned a few things about our system for feedstock tokens and\\ngeneral maintenance of our CI service integrations. We probably should\\nhave known them already, but here we are.\\n\\n- We used the same feedstock token across multiple CI services. This\\n  limited our ability to immediately invalidate tokens associated with\\n  a single CI service and exposed all services if any single service\\n  had an incident.\\n- Our token system only allowed one valid token per feedstock. This\\n  limitation means that we cannot recover from partially failed token\\n  resets/rotations and are subject to race conditions during the\\n  reset/rotation process that can cause failed package uploads.\\n- We need to be more proactive about cleaning up deprecated/removed CI\\n  services. The use of CircleCI in `conda-forge` has been deprecated\\n  for quite a while. Had we taken the time, and had the foresight, to\\n  remove all of our secrets from CircleCI when it was deprecated, we\\n  could have avoided the security incident all together.\\n\\nWe have begun retooling our system for feedstock tokens in order to fix\\nthe issues identified above and allow us to have more flexibility in\\nresponding to security incidents. We have also started the process of\\ndecommissioning several of our old CI services. These changes will take\\ntime to implement. You can follow the progress on our various public\\nissue trackers.\\n\\n## Closing Thoughts & What can you do?\\n\\nWe, the `conda-forge` core dev team, want to thank everyone for their\\npatience and support as we have responded to the various security\\nincidents and bugs detailed above. It goes without saying that the\\npublic nature of `conda-forge`\'s infrastructure carries risks. On the\\nother hand, by being public, anyone can look and verify our artifact\\nbuilds. Security for `conda-forge` is about reducing risk, and we will\\ncontinue to do our best.\\n\\nAs a reminder, we do not recommend that you use `conda-forge` in\\nenvironments with sensitive information. `conda-forge`\'s software is\\nbuilt by our users and the core dev team cannot verify or guarantee that\\nthis software is not malicious or has not been tampered with.\\n\\nOur best defense against security incidents in `conda-forge` is you! Our\\nfeedstock maintainers are in the best position to notice incidents and\\nissues. Please responsibly report anything you find to us at\\n`condaforge+security@gmail.com`."},{"id":"/2022/08/26/outreachy-wrap-up-blog-2022","metadata":{"permalink":"/blog/2022/08/26/outreachy-wrap-up-blog-2022","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2022-08-26-outreachy-wrap-up-blog-2022.md","source":"@site/blog/2022-08-26-outreachy-wrap-up-blog-2022.md","title":"Outreachy 2022 Wrap-up Blog","description":"This blog is about my work during my Outreachy internship with","date":"2022-08-26T00:00:00.000Z","formattedDate":"August 26, 2022","tags":[{"label":"Outreachy","permalink":"/blog/tags/outreachy"}],"readingTime":4.805,"hasTruncateMarker":true,"authors":[{"name":"Surbhi Sharma","title":"Outreachy intern","url":"https://github.com/ssurbhi560","image_url":"https://github.com/ssurbhi560.png","imageURL":"https://github.com/ssurbhi560.png"}],"frontMatter":{"authors":[{"name":"Surbhi Sharma","title":"Outreachy intern","url":"https://github.com/ssurbhi560","image_url":"https://github.com/ssurbhi560.png","imageURL":"https://github.com/ssurbhi560.png"}],"tags":["Outreachy"]},"unlisted":false,"prevItem":{"title":"CircleCI Security Incident","permalink":"/blog/2023/03/12/circle-ci-security-breach"},"nextItem":{"title":"GPU enabled TensorFlow builds on conda-forge","permalink":"/blog/2021/11/03/tensorflow-gpu"}},"content":"This blog is about my work during my Outreachy internship with\\n[conda-forge](https://conda-forge.github.io). Before that a little about\\nme - I am [Surbhi](https://github.com/ssurbhi560), an Outreachy intern\\nwith conda-forge for the May-August 2022 cohort and I worked on\\ndocumenting the conda-forge ecosystem.\\n\\n\x3c!--truncate--\x3e\\n\\nThe first issue I started working on when the internship began was\\n[Better anchoring of\\nannouncements(#1611)](https://github.com/conda-forge/conda-forge.github.io/issues/1611).\\nThe goal of this issue was to fix the anchor for each year and also\\nspecific announcements in the Announcements section so as to provide\\nbetter navigation of the [Announcements\\npage](https://conda-forge.org/docs/user/announcements.html). This was\\nalso the time when I was feeling quite overwhelmed and anxious since I\\nwas just starting and was unsure if I would be able to give my best. But\\nthanks to my awesome mentors\\n[@Katherine](https://github.com/kathatherine) and\\n[@Matt](https://github.com/beckermr), who have always been so helpful,\\nI was able to have a good start. We solved this issue in two parts. The\\nfirst part was to add anchors to each year which is solved with [Improve\\nanchors for each year in the Announcements section.\\n(#1766)](https://github.com/conda-forge/conda-forge.github.io/pull/1766),\\nand the second part was adding anchors to each announcement and fixing\\nthe RSS feed.\\n\\nThe part of the documentation I focused on after completing the first\\nissue was [Maintainers\'\\nDocumentation](https://conda-forge.org/docs/maintainer/00_intro.html).\\nMany open issues needed to be taken care of to make the Maintainers\'\\ndocumentation more useful and accessible for new maintainers. The open\\ntickets that we have worked on are:\\n\\n1.  [Document extras feedstock-name\\n    (#1769)](https://github.com/conda-forge/conda-forge.github.io/issues/1769)\\n    and [Explain how to become a maintainer\\n    (#1331)](https://github.com/conda-forge/conda-forge.github.io/issues/1331).\\n    Closed with [add extra section-recipe maintainer and feedstock-name\\n    (#1772)](https://github.com/conda-forge/conda-forge.github.io/pull/1772).\\n\\n    > As we started with improving the Maintainer documentation, these\\n    > were the issues we picked first to work on. The first issue was\\n    > documenting how maintainers can use the \\"feedstock-name\\" directive\\n    > for naming feedstocks differently than their package names in\\n    > staged recipes. The second issue was documenting how one should\\n    > become a package maintainer.\\n\\n2.  [Add more steps in Improve the documentation section\\n    (#1651)](https://github.com/conda-forge/conda-forge.github.io/issues/1651).\\n    Closed with [Update \\"Improve the documentation\\" section with more\\n    steps\\n    (#1776)](https://github.com/conda-forge/conda-forge.github.io/pull/1776).\\n\\n    > In this issue we added some additional steps for people who would\\n    > like to start contributing to conda-forge, especially to\\n    > documentation.\\n\\n3.  [Add more information about Grayskull in the documentation itself\\n    (#1655)](https://github.com/conda-forge/conda-forge.github.io/issues/1655).\\n    Closed with\\n    [#1777](https://github.com/conda-forge/conda-forge.github.io/pull/1777).\\n\\n    > The documentation on Grayskull in docs lacked the answers to\\n    > questions like what exactly Grayskull is and how one should use\\n    > Grayskull to generate a recipe. With this issue, we added more\\n    > documentation on Grayskull for users.\\n\\n4.  [Clarify feedstock LICENSE.txt\\n    (#803)](https://github.com/conda-forge/conda-forge.github.io/issues/803).\\n    Closed with [Add Feedstock repository structure section\\n    (#1786)](https://github.com/conda-forge/conda-forge.github.io/pull/1786).\\n\\n    > The docs for contributing and maintaining conda recipes discuss\\n    > when and how to distribute the license for a particular package.\\n    > The auto-generated feedstock repositories also include a license\\n    > in the root, which is different from the related package license.\\n    > With this issue, we added documentation on the differences between\\n    > those two licenses and briefly explained the feedstock repository\\n    > structure.\\n\\n5.  [DOC: New maintainer\\n    (#1117)](https://github.com/conda-forge/conda-forge.github.io/issues/1117).\\n    Closed with [Add \\"How regro-cf-autotick-bot create version update\\n    PR?\\" section.\\n    (#1788)](https://github.com/conda-forge/conda-forge.github.io/pull/1788).\\n\\n    > With this issue we improved docs for the new maintainers and the\\n    > working of the bot. A \\"How does `regro-cf-autotick-bot` create\\n    > automatic version updates?\\" section was added to the docs, which\\n    > explains the whole process of creating an automated version update\\n    > PRs by bot.\\n\\n6.  [Add Perl package hints to documentation\\n    (#1536)](https://github.com/conda-forge/conda-forge.github.io/issues/1536).\\n    Working on this\\n    [#1790](https://github.com/conda-forge/conda-forge.github.io/pull/1790).\\n\\n    > With this issue we added \u200b\u200bpackaging instructions for Perl packages\\n    > with different build systems in the documentation.\\n\\n7.  [DOC: Update documentation about tokens\\n    (#1532)](https://github.com/conda-forge/conda-forge.github.io/issues/1532).\\n    Closed with\\n    [#1793](https://github.com/conda-forge/conda-forge.github.io/pull/1793).\\n\\n    > Feedstocks have stopped storing encrypted tokens to upload\\n    > packages, but outdated information on tokens was still present in\\n    > the documentation. With this issue we removed the outdated\\n    > information and also added a new section \\"How to update your\\n    > feedstock token?\\" for maintainers.\\n\\n8.  [Improve the documentation on arch_rebuild.txt\\n    (#1668)](https://github.com/conda-forge/conda-forge.github.io/issues/1668).\\n    Closed with\\n    [#1794](https://github.com/conda-forge/conda-forge.github.io/pull/1794).\\n\\n    > With this issue we improved the documentation on\\n    > `arch_rebuild.txt` and how maintainers can add a feedstock to\\n    > `arch-rebuild.txt` if it requires rebuilding with different\\n    > architectures/platforms (such as ppc64le or aarch64).\\n\\n9.  [Document migrators\\n    (#1355)](https://github.com/conda-forge/conda-forge.github.io/issues/1355),\\n    [Update migration docs\\n    (#862)](https://github.com/conda-forge/conda-forge.github.io/issues/862),\\n    and [document migrators\\n    (#737)](https://github.com/conda-forge/conda-forge.github.io/issues/737)\\n    . Closed with [Documenting Migrators and Migrations.\\n    (#1801)](https://github.com/conda-forge/conda-forge.github.io/pull/1801).\\n\\n    > With these, we added more documentation on migrations and\\n    > migrators, which would help maintainers find answers to questions\\n    > like - What is a migrator/migration, and what does it do? When can\\n    > (and why would) they should reject a migration PR? And so on.\\n\\n10. [Add a section in docs on security aspects of conda-forge\\n    (#1808)](https://github.com/conda-forge/conda-forge.github.io/issues/1808).\\n    Closed with\\n    [#1812](https://github.com/conda-forge/conda-forge.github.io/pull/1812).\\n\\n    > Currently, information regarding the security considerations of\\n    > conda-forge builds is scattered throughout the documentation, and\\n    > therefore it is hard to find and read. With this issue, we will\\n    > put all the information together in one place, which will help\\n    > maintainers and users to know more about how conda-forge secures\\n    > its packages and infrastructure.\\n\\nI met some wonderful people during the internship who helped me with all\\nmy questions and doubts that I had. The experience during the internship\\nalso helped me get better opportunities after completing the Outreachy\\ninternship. I have learned so many things during the internship that it\\nwould make a long list if I were to write all of those. But the most\\nimportant things I learned are:\\n\\n- The importance of documentation and how to write good documentation.\\n- The best practices to follow while writing documentation.\\n- More about conda-forge and packaging tools.\\n\\nAnd above all, Outreachy helped me feel more confident about my skills\\nand overcome the imposter syndrome I had before. Thanks again to my\\nawesome mentors and the kind people of the conda-forge community! :)"},{"id":"/2021/11/03/tensorflow-gpu","metadata":{"permalink":"/blog/2021/11/03/tensorflow-gpu","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2021-11-03-tensorflow-gpu.md","source":"@site/blog/2021-11-03-tensorflow-gpu.md","title":"GPU enabled TensorFlow builds on conda-forge","description":"Tensorflow on Anvil","date":"2021-11-03T00:00:00.000Z","formattedDate":"November 3, 2021","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":3.545,"hasTruncateMarker":true,"authors":[{"name":"Wolf Vollprecht","title":"Member of conda-forge/core","url":"https://github.com/wolfv","imageURL":"https://github.com/wolfv.png","key":"wolfv"}],"frontMatter":{"authors":["wolfv"],"tags":["conda-forge"],"image":"https://i.imgur.com/pRdJaYw.png"},"unlisted":false,"prevItem":{"title":"Outreachy 2022 Wrap-up Blog","permalink":"/blog/2022/08/26/outreachy-wrap-up-blog-2022"},"nextItem":{"title":"Travis CI Security Incident","permalink":"/blog/2021/09/24/travis-security"}},"content":"![Tensorflow on Anvil](https://i.imgur.com/pRdJaYw.png)\\n\\nRecently we\'ve been able to add GPU-enabled TensorFlow builds to\\nconda-forge! This was quite a journey, with multiple contributors trying\\ndifferent ways to convince the Bazel-based build system of TensorFlow to\\nbuild CUDA-enabled packages. But we managed, [and the pull request got\\nmerged](https://github.com/conda-forge/tensorflow-feedstock/pull/157).\\n\\n\x3c!--truncate--\x3e\\n\\nWe now have a configuration in place that creates CUDA-enabled\\nTensorFlow builds for all conda-forge supported configurations (CUDA\\n10.2, 11.0, 11.1, and 11.2+). Building out the CUDA packages requires\\nbeefy machines -- on a 32 core machine it still takes around 3 hours to\\nbuild a single package. Our build matrix now includes 12 CUDA-enabled\\npackages & 3 CPU packages (because we need separate packages per Python\\nversion). As one can imagine, this isn\'t easily possible on an average\\n\\"home computer\\".\\n\\nFor this purpose, we have written an Ansible playbook that lets us boot\\nup cloud machines which then build the feedstock (using the\\n`build-locally.py` script). Thanks to the generous support\\nof OVH we were able to boot multiple 32-core virtual machines\\nsimultaneously to build the different TensorFlow variants.\\n\\nWe have open-sourced the [Ansible playbook in\\nGitHub](https://github.com/mamba-org/build-locally-ansible) and we\'re\\nworking towards making it (more) generally useful for other long-running\\nbuilds!\\n\\n![Running 3 builds in parallel on 32 cores ... still takes around 3 hours to finish](https://i.imgur.com/nvV6izV.jpg)\\n\\nWith the TensorFlow builds in place, conda-forge now has CUDA-enabled\\nbuilds for PyTorch and Tensorflow, the two most popular deep learning\\nlibraries.\\n\\nWe are still missing Windows builds for TensorFlow (CPU & CUDA,\\nunfortunately) and would love the community to help us out with that.\\nThere is an open PR, but it probably needs some poking in Bazel to get\\nit to pass: [conda-forge/tensorflow-feedstock#111](https://github.com/conda-forge/tensorflow-feedstock/pull/111).\\n\\nWe hope that these new GPU builds will enable many more packages to be\\nadded to the conda-forge channel! We are already looking forward to the\\n2.6.2 and 2.7 releases of TensorFlow and to adding Windows support in\\nthe future. We hope you enjoy this work.\\n\\n## Installation\\n\\nYou can now select between GPU enabled (default) and CPU packages using\\nthe `tensorflow-gpu` and `tensorflow-cpu` packages. Just run\\n\\n```bash\\nmamba install tensorflow-gpu -c conda-forge\\n# OR\\nconda install tensorflow-gpu -c conda-forge\\n```\\n\\nWhen installing the `tensorflow` package, the package resolution will\\nnow default to the GPU-enabled builds of tensorflow if the local machine\\nhas a GPU (these builds can be identified by \\"cuda\\" at the beginning\\nof the version number). Note that GPU-enabled packages can also work on\\nCPU-only machines, but one would need to override the enviornment\\nvariable `CONDA_OVERRIDE_CUDA` like below. This could be handy if you\\nare in a situation where your current node (e.g. login node) on an HPC\\ndoes not have GPUs, but the compute nodes with GPUs do not have internet\\naccess.\\n\\n```bash\\nCONDA_OVERRIDE_CUDA=\\"11.2\\" conda install tensorflow cudatoolkit>=11.2 -c conda-forge\\n# OR\\nCONDA_OVERRIDE_CUDA=\\"11.2\\" mamba install tensorflow cudatoolkit>=11.2 -c conda-forge\\n```\\n\\nNote that you should select the cudatoolkit version most appropraite for\\nyour GPU; currently, we have \\"10.2\\", \\"11.0\\", \\"11.1\\", and \\"11.2\\"\\nbuilds available where the the \\"11.2\\" builds are compatible with all\\ncudatoolkits>=11.2. You could also force a specific version of\\n`cudatoolkit` by specifying it like above. Moreover, you could ensure\\nyou get a sepcific build of tensorflow by appending the package name\\nlike `tensorflow==2.7.0=cuda*` or `tensorflow==2.7.0=cuda112*`. If you\\nwant the slimmer \\"cpu-only\\" package, then you can install\\n`tensorflow-cpu` directly or equivalently `tensorflow==2.7.0=cpu*`. At\\nthe time of writing (February 2022), on a machine without a GPU, one\\nwould always get the `-cpu` variant unless overriden like\\nabove. This decision has been made to allow greater accessibility for\\nusers with limited bandwidth and resources.\\n\\n## Thanks to\\n\\n- Mark Harfouche (@hmaarrfk) & Ista Zahn (@izahn) for their initial\\n  work on the TensorFlow GPU builds, and all other TensorFlow\\n  maintainers. Uwe Korn (@xhochy) for his work on the Bazel scripts &\\n  TensorFlow -- and all the other maintainers of the [TensorFlow\\n  feedstock](https://github.com/conda-forge/tensorflow-feedstock)!\\n- NVIDIA for pushing cudatoolkit and cudnn on conda-forge that makes\\n  this possible\\n- OVH for their generous sponsoring of large build machines that we\\n  could use to build the recipes\\n- Bloomberg for their sponsorship of QuantStack\'s involvement with\\n  conda-forge\\n- Andreas Trawoger (@atrawog) for the Ansible scripts that this is\\n  based on\\n- Thorsten Beier (@derthorsten) and Adrien Delsalle (@adriendelsalle)\\n  for their contributions to the recipe"},{"id":"/2021/09/24/travis-security","metadata":{"permalink":"/blog/2021/09/24/travis-security","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2021-09-24-travis-security.md","source":"@site/blog/2021-09-24-travis-security.md","title":"Travis CI Security Incident","description":"On September 9, 2021 one of our core devs discovered that artifacts","date":"2021-09-24T00:00:00.000Z","formattedDate":"September 24, 2021","tags":[{"label":"security","permalink":"/blog/tags/security"}],"readingTime":1.82,"hasTruncateMarker":true,"authors":[{"name":"Matthew R. Becker","title":"Member of conda-forge/core","url":"https://github.com/beckermr","imageURL":"https://github.com/beckermr.png","key":"beckermr"}],"frontMatter":{"authors":["beckermr"],"tags":["security"]},"unlisted":false,"prevItem":{"title":"GPU enabled TensorFlow builds on conda-forge","permalink":"/blog/2021/11/03/tensorflow-gpu"},"nextItem":{"title":"Contributing Packages To conda-forge Using Grayskull","permalink":"/blog/2021/06/16/graykull-step-by-step"}},"content":"On September 9, 2021 one of our core devs discovered that artifacts\\nbuilding on Travis CI were being uploaded to our conda channel from PRs\\nrunning on forked repositories. A quick investigation revealed that\\nTravis CI was passing encrypted secrets to PR builds on forks. Further\\nexamination of our logs and artifacts indicated that this had been\\nhappening since about September 3, 2021. This security bug was\\nsubsequently confirmed by Travis CI. See this\\n[CVE](https://nvd.nist.gov/vuln/detail/CVE-2021-41077) for more details\\non this incident. **As far as we know, there were no actual exploits\\nagainst conda-forge which used this vulnerability.**\\n\\n\x3c!--truncate--\x3e\\n\\n## Our Response\\n\\nWe took the following steps to respond to this incident.\\n\\n1.  We immediately turned off all builds on Travis CI by suspending the\\n    Travis CI GitHub App.\\n2.  We immediately disclosed the bug to Travis CI through our contacts\\n    there.\\n3.  Once Travis CI indicated to us that they were ready, we rotated all\\n    feedstock tokens and later our anaconda.org token for our staging\\n    channel. The anaconda.org token for the main `conda-forge` channel\\n    was never disclosed in this incident. Further, only ~70 feedstocks\\n    had their tokens exposed in this incident.\\n4.  We examined our artifacts and marked as broken any artifacts that\\n    were uploaded from PRs. We think we found everything, but we are not\\n    completely sure. Our criterion for marking things broken was more\\n    generous than it needed to be.\\n5.  We issued PRs to rebuild any broken artifacts via our bots.\\n6.  We put in changes to `conda-smithy` to help prevent inadvertent\\n    uploads of artifacts from PRs in the future.\\n\\n## Closing Thoughts & What can you do?\\n\\nI (MRB) want to recognize the quick work of our core dev team in\\nhandling this incident. It goes without saying that the public nature of\\n`conda-forge`\'s infrastructure carries risks. On the other hand, by\\nbeing public, anyone can look and verify our artifact builds. Security\\nfor `conda-forge` is about reducing risk and we will continue to do our\\nbest.\\n\\nOur best defense against security incidents in `conda-forge` is _you_!\\nOur feedstock maintainers are in the best position to notice incidents\\nand issues. Please responsibly report anything you find to us at\\n`condaforge+security@gmail.com`."},{"id":"/2021/06/16/graykull-step-by-step","metadata":{"permalink":"/blog/2021/06/16/graykull-step-by-step","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2021-06-16-graykull-step-by-step.md","source":"@site/blog/2021-06-16-graykull-step-by-step.md","title":"Contributing Packages To conda-forge Using Grayskull","description":"When contributing packages to conda-forge, Grayskull can make your life","date":"2021-06-16T00:00:00.000Z","formattedDate":"June 16, 2021","tags":[{"label":"grayskull","permalink":"/blog/tags/grayskull"},{"label":"outreachy","permalink":"/blog/tags/outreachy"}],"readingTime":1.48,"hasTruncateMarker":true,"authors":[{"name":"Mahe","title":"Outreachy intern","url":"https://github.com/ForgottenProgramme","image_url":"https://github.com/ForgottenProgramme.png","imageURL":"https://github.com/ForgottenProgramme.png"}],"frontMatter":{"authors":[{"name":"Mahe","title":"Outreachy intern","url":"https://github.com/ForgottenProgramme","image_url":"https://github.com/ForgottenProgramme.png","imageURL":"https://github.com/ForgottenProgramme.png"}],"tags":["grayskull","outreachy"]},"unlisted":false,"prevItem":{"title":"Travis CI Security Incident","permalink":"/blog/2021/09/24/travis-security"},"nextItem":{"title":"Conda-forge Outreachy","permalink":"/blog/2021/02/02/outreachy"}},"content":"When contributing packages to conda-forge, Grayskull can make your life\\nmuch easier. Grayskull generates recipes for Python packages hosted on\\nPyPI.\\n\\n\x3c!--truncate--\x3e\\n\\nAs the\\n[introduction](https://github.com/conda-incubator/grayskull#introduction)\\nfor Grayskull reads; \\"The main goal of this project is to generate\\nconcise recipes for conda-forge.\\" In this tutorial we learn how to\\ncontribute a Python package to the conda-forge channel using Grayskull\\nto generate the recipe.\\n\\nLet us get started.\\n\\n1.  Install `grayskull` using `conda` through the `conda-forge` channel:\\n\\n    ```\\n    $ conda install -c conda-forge grayskull\\n    ```\\n\\n2.  Fork and clone the conda-forge [staged-recipes\\n    repository](https://github.com/conda-forge/staged-recipes) from\\n    GitHub.\\n\\n3.  Checkout a new branch from the `master branch`.\\n\\n4.  Through CLI, cd inside the \'staged-recipes/recipes\' directory.\\n\\n5.  Call `grayskull` and pass the `pypi` repository, followed by the\\n    name of the package you want to contribute to conda-forge. For\\n    example: `grayskull pypi abc`\\n\\n    Or you could use `grayskull pypi abc --strict-conda-forge` to remove\\n    some selectors which are not necessary for conda-forge and adapt\\n    recipes to fit better in the conda-forge ecosystem.\\n\\n    Grayskull will create a folder with the same name as the package (in\\n    this case: \'abc\') in the \'recipes\' folder of the \'staged-recipes\'\\n    directory. This folder will contain the `meta.yaml` file and also\\n    the license file if the package includes a license in the PyPI\\n    distribution.\\n\\n6.  Go through the generated `meta.yaml` file. For simpler packages, the\\n    generated recipes are nearly perfect, but for some packages you\\n    might need to make certain tweaks.\\n\\n7.  Commit and push the changes. `git add recipe/abc/meta.yaml`\\n    `git commit -m \\"add a commit message\\"` `git push`\\n\\n8.  Create a PR.\\n\\n9.  Once the CI is passing, post a comment saying:\\n    `This is ready for review` `@conda-forge-admin, please ping team`\\n\\nOnce the PR gets merged, your package will be available on the\\nconda-forge channel. Tada! It\'s that easy."},{"id":"/2021/02/02/outreachy","metadata":{"permalink":"/blog/2021/02/02/outreachy","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2021-02-02-outreachy.md","source":"@site/blog/2021-02-02-outreachy.md","title":"Conda-forge Outreachy","description":"Conda-forge is participating in the upcoming round of","date":"2021-02-02T00:00:00.000Z","formattedDate":"February 2, 2021","tags":[{"label":"outreachy","permalink":"/blog/tags/outreachy"}],"readingTime":5.715,"hasTruncateMarker":true,"authors":[{"name":"Vinicius Douglas Cerutti","title":"Member of conda-forge/core","url":"https://github.com/viniciusdc","imageURL":"https://github.com/viniciusdc.png","key":"viniciusdc"}],"frontMatter":{"authors":["viniciusdc"],"tags":["outreachy"]},"unlisted":false,"prevItem":{"title":"Contributing Packages To conda-forge Using Grayskull","permalink":"/blog/2021/06/16/graykull-step-by-step"},"nextItem":{"title":"2020 in Review","permalink":"/blog/2020/12/26/year-in-review"}},"content":"Conda-forge is participating in the upcoming round of\\n[Outreachy](https://www.outreachy.org/) i.e May 2021 to August 2021. The\\ngoal of this program is to increase participation from under-represented\\ngroups in free and open-source software. Outreachy is organized by\\n[Software Freedom Conservancy](https://sfconservancy.org/).\\n\\n\x3c!--truncate--\x3e\\n\\n## Participant Application Process:\\n\\nFirst, please review the Outreachy Eligibility and Application\\nInformation page to learn more about eligibility for Outreachy.\\n\\n## Steps for applicants to conda-forge:\\n\\n1. Confirm your eligibility on the Outreachy site\\n2. Look at the Conda-forge projects available on the Outreachy site,\\n   consider your options, and if you have questions, communicate with the\\n   project mentors.\\n3. Begin by contributing to the project by looking at our [issues\\n   page](https://github.com/conda-forge/conda-forge.github.io/issues).\\n   As you make contributions, record them on the Outreachy site.\\n4. Once you have made a few contributions, begin to write your application.\\n   Ask the mentors to review the application before you submit it.\\n\\n## Participant Expectations\\n\\nYou will be working full-time on your project for three months. You will\\nmeet with your mentor(s) frequently and participate in the open-source\\ndevelopment process -- writing code, reviewing code, testing, and so\\non. You will be expected to write a blog entry each week.\\n\\n## Project Contribution Information\\n\\nAs part of the application process, all applicants must make at least\\none contribution to be accepted as an intern for this project. Only\\napplicants who make a contribution will be eligible to be accepted as\\ninterns.\\n\\nWhile we don\'t have one we highly recommend the first-time contributor\\nto be a conda user and/or submit a package to conda-forge via\\n[staged-recipes](https://github.com/conda-forge/staged-recipes). That\\nwill ensure the contributor understands the value of what we do and\\nmeans that they are willing to participate in our community.\\n\\nApplicants can contribute to this project through the [project\\nrepository or contribution page](https://conda-forge.org/#contribute).\\nThe project uses an [issue\\ntracker](https://github.com/conda-forge/conda-forge.github.io/issues) to\\nkeep information about bugs to fix, project features to implement,\\ndocumentation to write, and more. Applicants can look for\\nnewcomer-friendly issues to use for their first contributions by looking\\nfor the following issue tags in the project issue\\n[tracker](https://github.com/conda-forge/conda-forge.github.io/issues):\\nDocs, Good first issue\\n\\nWe here at [conda-forge](https://conda-forge.org/#contribute) have a\\nlarge number of potential Outreachy endeavors around documentation,\\nmaintenance, and development. These tasks are high-impact, affecting the\\nentire conda-forge ecosystem. They also cover multiple systems including\\ndatabases, conda\'s CDN provider, continuous integration providers, and\\nuser interactions on GitHub.\\n\\n## How do I work with the conda-forge community?\\n\\nOutreachy applicants can get help and feedback from both mentors and\\ncommunity members. Community members discuss their contributions in a\\npublic chat. Outreachy applicants can often learn from those\\ndiscussions.\\n\\nPlease introduce yourself on the public project chat:\\n\\n- Gitter - [Follow this\\n  link](https://gitter.im/conda-forge/conda-forge.github.io) to join this\\n  project\'s public chat.\\n- Outreachy mentors will often be in the community public chat. The\\n  project mentor\'s usernames are: `@viniciusdc`.\\n\\nHere are some ready-to-go ways you can get started contributing on your\\nown.\\n\\n- Find an open issue to tackle or report a bug to the issue tracker;\\n- Don\'t be afraid to communicate: Ask if you can help write a new\\n  feature or help Automate project setups;\\n- Improving current tooling and testing features is always welcome.\\n\\nAs this project main goal is enhancing our current documentation, here\\nare some preliminary tasks that you can inspect to get ideas:\\n\\n- Write and improve the project\'s documentation;\\n- Link to duplicate issues, and suggest new issue labels, to keep\\n  things organized;\\n- Go through open issues and suggest closing old ones;\\n- Ask clarifying questions on recently opened issues to move the\\n  discussion forward;\\n- We also have issues regarding the main functionalities of our bot,\\n  in particular the autotick bot. You could find some new information\\n  or ideas for your contributing proposals.\\n\\n## Good starter tasks:\\n\\n### Small Starter Tasks\\n\\nAs with most organizations, there are lots of small issues that need\\naddressing usually related to problems such as bad recipes, old\\ndocumentation and others. These will make good first issues to resolve\\nor \\"update\\". This will also be an opportunity to familiarise yourself\\nwith the conda-forge environment.\\n\\n### Larger tasks\\n\\nThere are a few potential larger tasks that can come after a few smaller\\ntask contributions. These are included into our three main bases:\\n\\n- [Users](https://conda-forge.org/docs/user/00_intro.html): In this\\n  case, some good starter tasks are mainly checking the actual\\n  contents of conda-forge users documentations, and ideas to better\\n  express its contents.\\n- [Maintainers](https://conda-forge.org/docs/maintainer/00_intro.html):\\n  There are a bunch of missed topics in this area, some information\\n  have to be updated or rewritten for better understanding. Writing a\\n  complete guide containing the actual steps and standard model for a\\n  package recipe, building process (just a simple discussion) and how\\n  conda-forge bot recognize defective licenses, recipes and packages\\n  in general is highly welcomed. For further understanding of the\\n  general system check [this\\n  link](https://conda-forge.org/docs/maintainer/infrastructure.html).\\n  - It can be funny to say, but lots of helpful ideas and bug\\n    solutions appear on our gitter channel, so if you have time to\\n    write guides about them... it\'s also an incredible task.\\n- [And organization](https://conda-forge.org/docs/orga/00_intro.html)\\n  Our environment is changing everyday, because of that a lot of\\n  information is lost in this process or even worse, not documented at\\n  all! which leads to some difficulties inserting new members to\\n  develop and further enhance the current process.\\n  - The related work on this matter is highly welcomed and for a\\n    better grasp of the situation you can start with this\\n    [guideline](https://conda-forge.org/docs/orga/guidelines.html)\\n    and read some of our posts in our\\n    [blog](https://conda-forge.org/blog/blog/)\\n  - Revitalizing ideas/projects for the conda-forge blog are\\n    definitely welcomed;\\n  - Currently we have some interesting projects going on inside our\\n    ecosystem, which in return will need good documentation... Some\\n    of the projects conda-forge is affiliated include the [auto-tick\\n    bot](https://github.com/regro/cf-scripts),\\n    [symbol-exporter](https://github.com/symbol-management/symbol-exporter)\\n    and a new service we are eager to start developing is the\\n    [distributed-bot](https://github.com/regro/cf-scripts/issues/1367).\\n    All of them have a great coverage of subjects and lots of people\\n    to help and give advice about the service structure and\\n    functionalities.\\n\\n## Improving the documentation\\n\\nYou can help improve the documentation as it is version-controlled in\\nthe conda-forge.github.io repository on GitHub. The source text is\\nstored there in the `src/subdirectory` and is formatted using [Python\'s\\nreStructuredText system](https://wiki.python.org/moin/reStructuredText).\\n\\nYou can propose quick edits directly through the GitHub website, if you\\nhave an account there --- for instance, this\\n[link](https://github.com/conda-forge/conda-forge.github.io/edit/master/src/user/contributing.rst)\\nwill take you directly to a web-based editor for this section page in\\nour\\n[docs](https://conda-forge.org/docs/user/contributing.html#improve-docs).\\nIn general, the file corresponding to each page in the GitHub browser\\nhas a little pencil icon in its top-right that lets you open it up for\\nediting.\\n\\nThe more manual process is as follows:\\n\\n- Fork the conda-forge.github.io repository to your own GitHub user\\n  account.\\n- Clone that fork onto your computer.\\n- Check out a new branch deriving from master to do your work.\\n- Make and commit your changes.\\n- Submit a pull request to the main repository proposing your changes.\\n\\nHappy editing!"},{"id":"/2020/12/26/year-in-review","metadata":{"permalink":"/blog/2020/12/26/year-in-review","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-12-26-year-in-review.md","source":"@site/blog/2020-12-26-year-in-review.md","title":"2020 in Review","description":"As 2020 winds down, the Core team thought it\'d be fun to review some of","date":"2020-12-26T00:00:00.000Z","formattedDate":"December 26, 2020","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":2.36,"hasTruncateMarker":false,"authors":[{"name":"conda-forge/core","title":"The conda-forge core team","url":"https://github.com/orgs/conda-forge/teams/core","imageURL":"https://github.com/conda-forge.png","key":"core"}],"frontMatter":{"authors":["core"],"tags":["conda-forge"]},"unlisted":false,"prevItem":{"title":"Conda-forge Outreachy","permalink":"/blog/2021/02/02/outreachy"},"nextItem":{"title":"Package Distribution and the anaconda.com Terms of Service","permalink":"/blog/2020/11/20/anaconda-tos"}},"content":"As 2020 winds down, the Core team thought it\'d be fun to review some of\\nthe big accomplishments our community has made this year.\\n\\n## Strong Growth\\n\\nThe `conda-forge` community has grown immensely this year. Here are some\\nnumbers to help give you an idea of the scale of our growth.\\n\\n- The community has added 3,751 new, unique `conda` packages this\\n  year, along with a corresponding number of new feedstocks.\\n- For the majority of 2020, the `conda-forge` channel on\\n  `anaconda.org` exceeded 100 million downloads per month.\\n- In July of 2020, the `conda-forge` channel passed 2 billion total,\\n  all-time downloads.\\n- We\'ve grown our core developer community, adding seven new members\\n  to the `conda-forge` Core team and at least two members to the\\n  `staged-recipes` team.\\n- We now have over 2,500 recipe maintainers in the `conda-forge`\\n  GitHub organization.\\n\\n## Big New Features\\n\\nWe\'ve also shipped a ton of big updates to our core infrastructure this\\nyear. These updates include\\n\\n- `PyPy` **support**: We added support for `PyPy` 3.6 and now supply\\n  one of the biggest stacks of `PyPy`-enabled packages in the `PyPy`\\n  ecosystem.\\n- **automerge**: We now support the automatic merging of PRs on\\n  feedstocks using the `automerge` label or through an opt-in setting\\n  in the `conda-forge.yml`.\\n- `R` **4.0 migration**: This migration was the first one to use our\\n  `automerge` infrastructure at scale. With it, we completed a\\n  complete rebuild/upgrade of the `R` ecosystem in about a week.\\n- `Python` **updates**: We deprecated `Python` 2.7, completed the\\n  `Python` 3.8 migration, and got about 75% of the way through the\\n  `Python` 3.9 migration.\\n- **compiler upgrades**: We upgraded our compiler infrastructure to\\n  `GCC` 9 and `clang` 11.\\n- **CentOS 7 and CentOS 6 EOL**: We shipped an option to enable our\\n  compilers to use the CentOS 7 `sysroot` in preparation for the\\n  CentOS 6 EOL. We hope to complete the move to CentOS 7 early next\\n  year.\\n- **miniforge**: We built our own standalone, `miniconda`-like\\n  installers. These support a broad range of platforms, including\\n  `osx-arm64` and `linux-aarch64`.\\n- **standalone Windows stack**: We fully decoupled our Windows recipes\\n  from the `defaults` channel by rebuilding the `msys2` recipes.\\n- **Apple silicon support**: We added support for Apple silicon with\\n  our `osx-arm64` platform. This platform is our first one to use a\\n  fully cross-compiled infrastructure.\\n- **CUDA support**: We added support for building CUDA packages on\\n  windows and added CUDA 11.0 support.\\n\\n---\\n\\nWe know that this year has been extremely difficult for so many of our\\ncommunity members and that the fantastic success of `conda-forge` would\\nnot have been possible without the active participation and support of\\nour community. **Thank you everyone so much for the work you put into**\\n`conda-forge` **this year, making it the wonderful, community-led\\nresource that it is.**\\n\\nWe wish everyone a happy, healthy, and peaceful new year!"},{"id":"/2020/11/20/anaconda-tos","metadata":{"permalink":"/blog/2020/11/20/anaconda-tos","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-11-20-anaconda-tos.md","source":"@site/blog/2020-11-20-anaconda-tos.md","title":"Package Distribution and the anaconda.com Terms of Service","description":"Various members of the community have raised questions publicly and","date":"2020-11-20T00:00:00.000Z","formattedDate":"November 20, 2020","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":1.81,"hasTruncateMarker":true,"authors":[{"name":"conda-forge/core","title":"The conda-forge core team","url":"https://github.com/orgs/conda-forge/teams/core","imageURL":"https://github.com/conda-forge.png","key":"core"}],"frontMatter":{"authors":["core"],"tags":["conda-forge"]},"unlisted":false,"prevItem":{"title":"2020 in Review","permalink":"/blog/2020/12/26/year-in-review"},"nextItem":{"title":"macOS ARM builds on conda-forge","permalink":"/blog/2020/10/29/macos-arm64"}},"content":"Various members of the community have raised questions publicly and\\nprivately about the implications of Anaconda\'s new Terms of Service\\n(TOS) on `anaconda.com`. First of all, we understand your concerns. We\\nwould like to explain a bit how `conda-forge` works, how the TOS change\\naffects us and `conda-forge` users, and what our plans as a community\\nare for the future.\\n\\n\x3c!--truncate--\x3e\\n\\nWhat makes it non-surprising [that no other free conda package\\ndistribution services have appeared] is that, at the moment, any third\\nparty channel like `conda-forge` is free. The TOS change does not apply\\nto `conda-forge`, nor to other channels hosted on anaconda.org; the TOS\\nchange in question applies only to the \\"defaults\\" channel and other\\nsoftware hosted on repo.anaconda.com.\\n\\nWhile having alternative hosting is in our plans, we cannot afford the\\ncosts. We are just a community of volunteers. We have experimented with\\nuploading the `conda-forge` artifacts to GitHub and continue to do so\\n(see `regro/releases`). We also have put those artifacts behind an\\nexperimental repodata server. One of our core devs (@wolfv) is working\\nto setup `quetz` with `conda-forge` artifacts as well.\\n\\nIt is very important to recognize that Anaconda Inc kindly donates use\\nof their hosting and employee time to us, absorbing all of these costs.\\nThey host about 1.8 TB of our data and serve over 100 million downloads\\nof artifacts from that data each month. This is a highly significant\\ndonation and `conda-forge` would not exist without it. Anaconda Inc\\nemployees also provide help with maintaining some of the most complex\\npackage recipes in conda-forge.\\n\\nNote that Anaconda Inc has also said that part of the revenue from the\\nTOS change will be donated to OSS projects. (see this [blog\\npost](https://www.anaconda.com/blog/sustaining-our-stewardship-of-the-open-source-data-science-community)).\\nYou should be aware that `conda-forge` is a part of NumFOCUS, and so it\\nstands to benefit from the change in TOS, as do many other OSS projects.\\n\\nWe absolutely welcome help from the community to move our efforts on\\nbuilding out more hosting infrastructure for `conda-forge` forward. This\\ncould be anything from spending time developing `quetz` to providing\\nhosting/mirroring for our data. Please do get in contact with us if\\nyou\'d like to help out!"},{"id":"/2020/10/29/macos-arm64","metadata":{"permalink":"/blog/2020/10/29/macos-arm64","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-10-29-macos-arm64.md","source":"@site/blog/2020-10-29-macos-arm64.md","title":"macOS ARM builds on conda-forge","description":"A new platform osx-arm64 has been added to the build matrix of","date":"2020-10-29T00:00:00.000Z","formattedDate":"October 29, 2020","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":7.22,"hasTruncateMarker":true,"authors":[{"name":"Isuru Fernando","title":"Member of conda-forge/core","url":"https://github.com/isuruf","imageURL":"https://github.com/isuruf.png","key":"isuruf"}],"frontMatter":{"authors":["isuruf"],"tags":["conda-forge"]},"unlisted":false,"prevItem":{"title":"Package Distribution and the anaconda.com Terms of Service","permalink":"/blog/2020/11/20/anaconda-tos"},"nextItem":{"title":"The API Territory and Version Number Map","permalink":"/blog/2020/10/02/versions"}},"content":"A new platform `osx-arm64` has been added to the build matrix of\\nconda-forge. `osx-arm64` packages are built to run on upcoming macOS\\narm64 processors marketed as `Apple Silicon`. An installer for this\\nplatform can be found\\n[here](https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-MacOSX-arm64.sh).\\n\\n\x3c!--truncate--\x3e\\n\\nThis will install a conda environment with python and conda in it.\\nInstalled conda will be able to install packages like `numpy, scipy`.\\nCurrently there are about 100 packages out of 10000 packages pre-built\\nfor this platform.\\n\\nAll these packages are built on conda-forge\'s current macOS `x86_64`\\ninfrastructure. In order to do so, we have made lots of changes to the\\ninfrastructure including,\\n`conda, conda-build, conda-smithy, constructor, conda-forge-ci-setup` to\\nfacilitate cross-compiling which is the process of compiling a package\\nthat will run on a `host` platform (`osx-arm64` in our case), with the\\ncompilation done on a `build` platform (`osx-64` or `linux-64` in our\\ncase).\\n\\n`osx-arm64` is the first conda platform that is completely bootstrapped\\nusing conda-build\'s cross-compiling facility. Previously, when adding a\\nnew platform, conda-build was built with an existing python and pip\\nenvironment on the new platform. With cross-compiling, when the\\ncompilers and a sysroot is set up on a different platform, an existing\\nconda-build installation (on `osx-64` and `linux-64` in this case) will\\nbe able to start building packages right away.\\n\\n## Cross-compiling builds for `osx-arm64`\\n\\nIn order to cross compile packages for `osx-arm64` we need compilers.\\nSo, we first built `clang=11.0.0.rc1` which has support for targetting\\n`osx-arm64`. We also built `compiler-rt=11.0.0.rc1` as a universal build\\nsupport both `osx-64` and `osx-arm64`.\\n\\nLinker, archiver, `otool`, `install_name_tool` was built using the\\n[cctools-port project](https://github.com/tpoechtrager/cctools-port) by\\nThomas P\xf6chtrager.\\n\\nOne issue we ran into was that the macOS 11.0 Big Sur Beta 7 required\\nthat all executables and shared libraries be ad-hoc signed which is\\nsigning without a verified signature. On suggestion of `cctools-port`\\ndeveloper we added support to `cctools-port` to sign these executables\\nusing `ldid` which can be used on Linux as well as macOS to sign.\\n\\nUsing these, the first cross compiled package we built was `libcxx` to\\nfacilitate C++ builds. For the `osx-arm64` sysroot we used the\\n`MacOSX11.0.sdk` already installed on Azure pipelines and Travis-CI. Due\\nto licensing issues, we cannot distribute this, but it can be downloaded\\nfrom the Apple developer website even on Linux.\\n\\nWith clang we have a C/C++ compiler, but lack a Fortran compiler. We\\nused the [GCC fork for\\ndarwin-arm64](https://github.com/iains/gcc-darwin-arm64). First, a cross\\ncompiler (`build == host != target`) was built. Using that compiler, we\\nbuilt a `cross-native` compiler (`build != host == target`) which gave\\nuse the shared libraries like `libgfortran.dylib`.\\n\\nWe also added support for cross compiling rust programs to the rust\\npackages in conda and installing `rust_osx-64` on Linux will give you a\\ncompiler that will build packages for `osx-64`.\\n\\nAs we haven\'t done cross-compilation before, many packages needed to be\\nupdated. Most were trivial changes that we automated later on. These\\nincluded getting a newer `config.sub` to identify the new autotools\\nplatform `arm64-apple-darwin20.0.0`, adding options to CMake with the\\nenvironment variable `CMAKE_ARGS` to correctly set up the toolchain and\\nrecipes were update to use `cmake ${CMAKE_ARGS} ..`. Running tests when\\nbuilding were also disabled by guarding commands like `make check`,\\n`make test`, `ctest` with the env variable\\n`CONDA_BUILD_CROSS_COMPILATION`.\\n\\nCross-compiling python extensions is quite tricky as `distutils` is not\\nreally setup to do this. Thanks to the project\\n[crossenv](https://github.com/benfogle/crossenv) this is unofficially\\nsupported with a few quirks. With `crossenv`, we can run a python on the\\nbuild machine (`osx-64` or `linux-64` in this case) that acts like it is\\non `osx-arm64`. `crossenv` monkey-patches a few functions like\\n`os.uname` and sets up values like `_PYTHON_SYSCONFIG_DATA` to make\\npython running on `osx-64` or `linux-64` behave like `osx-arm64`. One\\nissue is that, monkey-patching `sys.platform` doesn\'t work and\\ntherefore if a python package in it\'s `setup.py` uses `sys.platform` to\\ndifferentiate OSes this will lead to unintended consequences if you are\\ncross-compiling from `linux-64`. Therefore, we have to use `osx-64` as\\nour `build` system when cross-compiling for `osx-arm64`. Note that\\npackages using `sysconfig.get_platform()` will get the correct platform.\\n\\nFor creating an installer for conda, we needed a standalone conda\\nexecutable to bootstrap the conda environment. For other platforms we\\nrelied on `conda-standalone` which is a standalone conda executable\\ncreated using `pyinstaller`. Since `pyinstaller` does not support\\ncross-compile, we decided to use `micromamba` as the bootstrapper and\\nadded features to `micromamba` so that it can function as the\\nbootstrapper.\\n\\n## How to add a `osx-arm64` build to a feedstock\\n\\nAll the below changes will be done by a bot and the packages the bot\\nwill send PRs to is determined by the list of packages at\\n[conda-forge-pinning](https://github.com/conda-forge/conda-forge-pinning-feedstock/blob/master/recipe/migrations/osx_arm64.txt)\\nand their dependences. If you would like to add support, please send a\\nPR adding the feedstock name to the above list. After that PR is merged,\\nyou can monitor the status at [conda-forge\\nstatus-page](https://conda-forge.org/status/#armosxaddition) and if a\\nparticular PR is stalled you can send a PR to the feedstock to fix it.\\n\\nFollowing instructions are for when you want to add support manually.\\n\\nAdd the following to `conda-forge.yml` (on Linux or OSX),\\n\\n```yaml\\nbuild_platform:\\n  osx_arm64: osx_64\\ntest: native_and_emulated\\n```\\n\\nYou can rerender using,\\n\\n```bash\\nconda smithy rerender\\n```\\n\\nFor python packages, add one or more of the following to\\n`recipe/meta.yaml` as needed, noting that you _must_ only add\\n`numpy`, `cython`, and/or `pybind11`\\nif they are used in `host:` as well,\\n\\n```yaml\\nrequirements:\\n  build:\\n    - python                                 # [build_platform != target_platform]\\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\\n    - cython                                 # [build_platform != target_platform]\\n    - numpy                                  # [build_platform != target_platform]\\n    - pybind11                               # [build_platform != target_platform]\\n```\\n\\nFor autotools package, add the following to `recipe/meta.yaml`,\\n\\n```yaml\\nrequirements:\\n  build:\\n    - gnuconfig   # [unix]\\n```\\n\\nand to `recipe/build.sh`,\\n\\n```bash\\n# Get an updated config.sub and config.guess\\ncp $BUILD_PREFIX/share/gnuconfig/config.* .\\n```\\n\\nFor cmake packages, add the following to `recipe/build.sh`,\\n\\n```bash\\ncmake ${CMAKE_ARGS} ..\\n```\\n\\nFor `meson` packages, add the following to `recipe/build.sh`,\\n\\n```bash\\nmeson ${MESON_ARGS} builddir/\\n```\\n\\n:::note\\nConda automatically creates a [cross build definition\\nfile](https://mesonbuild.com/Cross-compilation.html) when\\ncross-compiling, and adds the necessary argument to `${MESON_ARGS}` to\\npoint `meson` to that file. `${MESON_ARGS}` is only defined when\\ncross-compiling, not for normal builds.\\n:::\\n\\nFor rust packages, add the following to `recipe/meta.yaml`,\\n\\n```bash\\nrequirements:\\n  build:\\n    - {{ compiler(\'rust\') }}\\n```\\n\\nIf there\'s a line like `make check` in `recipe/build.sh` that cannot be\\nrun when cross-compiling, do the following,\\n\\n```bash\\nif [[ \\"$CONDA_BUILD_CROSS_COMPILATION\\" != \\"1\\" ]]; then\\n  make check\\nfi\\n```\\n\\nAfter these changes, another rerendering might be required.\\n\\nSome useful jinja variables,\\n\\n1.  `build_platform` - conda subdir for `BUILD_PREFIX`. eg:\\n    `linux-64`\\n2.  `target_platform` - conda subdir for `PREFIX`. eg: `osx-arm64`\\n\\nSome useful environment variables,\\n\\n1.  `build_platform`\\n2.  `target_platform`\\n3.  `CONDA_BUILD_CROSS_COMPILATION` - 1 if cross compiling\\n4.  `CMAKE_ARGS` - arguments to pass to cmake\\n5.  `CC_FOR_BUILD` - C compiler for build platform\\n6.  `CXX_FOR_BUILD` - C++ compiler for build platform\\n7.  `HOST` - a triplet for host passed to autoconf. eg:\\n    `arm64-apple-darwin20.0.0`\\n8.  `BUILD` - a triplet for build passed to autoconf. eg:\\n    `x86_64-conda-linux-gnu`\\n\\nSome useful configure options in `conda-forge.yml`\\n\\n1.  `build_platform` - a dictionary mapping `build` subdir to `host` subdir. eg:\\n\\n    ```yaml\\n    build_platform:\\n      osx_arm64: osx_64\\n      linux_ppc64le: linux_64\\n      linux_aarch64: linux_64\\n    ```\\n\\n2.  `test_on_native_only` - a boolean to turn off testing on cross\\n    compiling. If the tests don\'t require emulation (for eg: check\\n    that a file exists), then `test_on_native_only: false` will run\\n    the tests even when cross compiling.\\n\\n## Building locally\\n\\nFor building locally add the following in\\n`$HOME/conda_build_config.yaml`.\\n\\n```yaml\\nSDKROOT:\\n  - /path/to/MacOSX11.0.sdk\\n```\\n\\nAfter that, look for the config you want to run in `.ci_support` folder\\nin the root of the feedstock For eg: `.ci_support/osx_arm64_.yaml`. Then\\nrun,\\n\\n```bash\\nconda build recipe -m .ci_support/osx_arm64_.yaml -c conda-forge -c conda-forge/label/rust_dev\\n```\\n\\nThis should start a new build for `osx-arm64`.\\n\\n## Testing packages\\n\\nIn order to test packages intended to run on future Apple Silicon\\nhardware, Apple provides a machine called Developer Transition Kit\\n(DTK). Jonathan Helmus and Eli Rykoff has helped with testing these\\npackages on DTKs. Thanks to Eli Rykoff, we are now running tests for\\nthese packages as a daily cron job which has led to finding several bugs\\nin our cross compiling infrastructure and also bugs in our recipes.\\n\\nTo test cross compiled recipes, transfer the built conda package to the\\n`host` and run,\\n\\n```bash\\nconda build --test /path/to/package -c conda-forge\\n```\\n\\nThis work would not have been possible without the help of many people\\nincluding the upstream maintainers of compiler infrastructure (which\\nincludes conda, conda-build, cctools, tapi, cctools-port, ldid, llvm,\\nclang, compiler-rt, openmp, libcxx, crossenv, rust, gcc-darwin-arm64),\\n`conda-forge/help-osx-arm64` team including Matt Becker, Eli Rykoff and\\nUwe Korn who sent PRs to fix recipes, `conda-forge/bot` team and also\\nall the conda-forge maintainers of the 100 feedstocks who reviewed and\\nfixed PRs.\\n\\nIsuru Fernando"},{"id":"/2020/10/02/versions","metadata":{"permalink":"/blog/2020/10/02/versions","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-10-02-versions.md","source":"@site/blog/2020-10-02-versions.md","title":"The API Territory and Version Number Map","description":"tl;dr Depending on specific version numbers of underlying libraries may","date":"2020-10-02T00:00:00.000Z","formattedDate":"October 2, 2020","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":6.915,"hasTruncateMarker":true,"authors":[{"name":"Christopher J. \'CJ\' Wright","title":"Member of conda-forge/core","url":"https://github.com/cj-wright","imageURL":"https://github.com/cj-wright.png","key":"cj-wright"}],"frontMatter":{"authors":["cj-wright"],"tags":["conda-forge"]},"unlisted":false,"prevItem":{"title":"macOS ARM builds on conda-forge","permalink":"/blog/2020/10/29/macos-arm64"},"nextItem":{"title":"R 4.0 Migration Retrospective","permalink":"/blog/2020/07/11/r-4"}},"content":"tl;dr Depending on specific version numbers of underlying libraries may\\nbe too inaccurate and cause headaches as upstream libraries evolve and\\nchange. A more detailed approach is needed. In this post I outline\\ncurrent and potential work on a path towards a more complete inspection\\nof requirements based on APIs and dynamic pinning of libraries.\\n\\n\x3c!--truncate--\x3e\\n\\n## What Constitutes a Good Version Number\\n\\nVersion numbers should constitute a set that has the following\\nproperties\\n\\n1.  The set must be unbounded\\n2.  The set must be orderable (maybe)\\n\\nOf course sets that meet these requirements might not convey a lot of\\ninformation about the software they represent other than if two things\\nare equivalent and their comparative ages. Note that the requirement to\\nbe orderable may not be needed, but is generally useful when considering\\nthe idea of an \\"upgrade\\" since it provides a clear delineation between\\nolder and newer packages. In many cases, the structure of the version\\nnumber provides additional information. For some projects the version\\nnumber includes the date of the release, often using [cal\\nver](https://calver.org/). Many projects use [semantic\\nversioning](https://semver.org/), which attempts to encode information\\nabout the underlying source code\'s API in the version number.\\n\\n## Version Numbers and API Pinning\\n\\nOne of the most important places where version numbers are specified is\\nduring the pinning of APIs. Source code often requires specific APIs\\nfrom the libraries it uses. This requires a pin specifying which\\nversions of the underlying libraries can be used. The package manager\\nthen uses these pins to make certain a compatible environment is\\ncreated.\\n\\nHowever, these pins (or even the lack of pins) produce problems.\\nFirstly, the pins are a one-time, local statement about the current and\\nfuture, global ecosystem of packages. For instance a pin of `scipy` to\\nthe current major version number may not hold up over time, newer\\nversions of `scipy` may break the API while not changing the major\\nversion number. Similarly the lack of pin for `scipy` could be false as\\nthe API breaks. Even pins that establish firm upper and lower bounds may\\nbe false as new versions of the pinned library restore the missing API.\\nThese issues are particularly problematic for dependency systems that\\ntie the pins to a particular version of the source code, requiring a new\\nversion to be created to update the pins. Conda-Forge is able to avoid\\nsome of these issues via [repodata\\npatching](https://github.com/conda-forge/conda-forge-repodata-patches-feedstock),\\ndynamically updating a package\'s stated requirements. Overall this\\nprocess is fraught, as each package depends on different portions of a\\nlibrary\'s API, a version bump that breaks one package may leave others\\nunscathed.\\n\\n## A Potential Path Forward\\n\\nAll of the above issues are caused by the confusion of [the map for the\\nterritory](https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation).\\nThe map, in this case the version number of a library, can not\\naccurately represent the territory, the API itself. To fix this issue we\\nneed a more accurate description of the territory. Achieving this will\\nnot be easy, but I think there is an approach that gets close enough to\\nlimit the number of errors.\\n\\nWe need a programmatic way to check if a particular library, for a\\nparticular version, provides the required API. I think this can be\\nachieved iteratively, with each step providing additional clarity and\\ndifficulty of implementation. Note that in the steps below, I\'m using\\npython packaging as an example, but I imagine that these steps are\\ngeneral enough to apply to other languages and ecosystems.\\n\\n1.  Determine which libraries are requirements of the code, this is\\n    provided by tools like\\n    [depfinder](https://github.com/ericdill/depfinder) and are starting\\n    to be integrated into the Conda-Forge bot systems (although they are\\n    still highly experimental and being worked on).\\n2.  Determine if the a version of the library provides the needed\\n    modules. This could be accomplished by using depfinder to find the\\n    imports and use the mapping provided by\\n    [libcfgraph](https://github.com/regro/libcfgraph/tree/master/import_maps)\\n    between the import names and the versions of packages that ship\\n    those imports.\\n3.  Determine if an imported module provides the symbols being imported.\\n    This would require a listing of all the symbols in a given python\\n    module, including top level scoped variables, function names, class\\n    names, methods, etc.\\n4.  For callables determine if the used call signature matches the\\n    method or function definition.\\n\\nThe [depfinder](https://github.com/ericdill/depfinder) project has made\\nsignificant advances along this path, providing an easy to use tool to\\nextract accurate import and package requirement data from source code.\\nDepfinder even has cases to handle imports that are within code blocks\\nthat might make the requirement optional or use the python standard\\nlibrary. Future work on depfinder, including using more accurate maps\\nbetween imports and package names and providing metadata on package\\nrequirements that are collectively exhaustive (for instance imports of\\n`pyqt4` vs. `pyqt5` in a `try: except:` block), will provide even more\\naccurate information on requirements.\\n\\nAt each one of the above stages we can provide significant value to\\nusers, maintainers and source code authors by helping them to keep their\\nrequirements consistent and warning when there are conflicts.\\nConda-Forge can update its repodata as new versions of imported\\nlibraries are created, to properly represent if that version is API\\ncompatible with it\'s downstream consumers. Additionally the tables that\\nlist all the symbols and call signatures can be provided to 3rd party\\nconsumers that may want to patch their own metadata or check if a piece\\nof source code is self consistent in its requirements. This will also\\nhelp with the loosening of pins, creating more solvable environments for\\nConda-Forge and other packaging ecosystems. Furthermore, as this tooling\\nmatures and becomes more accurate it can be incorporated into the\\nConda-Forge bot systems to automatically update dependencies during\\nversion bumps and repodata patches, helping reduce maintenance burden.\\n\\nTools built from the symbol table can also have impacts far beyond\\nConda-Forge. For instance, the symbol tables could allow source code\\nauthors to have a line by line inspection of their code, revealing which\\nlines force the use of older or newer versions of dependencies. This\\ncould enable large scale migrations of source code with surgical\\nprecision, enabling developers to extract and re-write the few lines of\\ncode preventing the use of a new version of a library.\\n\\n## Caveats\\n\\nThere are some important caveats to this approach that need to be kept\\nin mind.\\n\\n1.  All of this work is aimed at understanding the API of a given\\n    library, this approach can not provide insight into the code inside\\n    of the API, or if changes there impact downstream consumers. For\\n    instance, version updates that fix bugs and security flaws in\\n    library code may not change the API at all. From this tooling\'s\\n    perspective there is no reason to upgrade since the API is not\\n    different. Of course there is a strong reason to upgrade in this\\n    case, since buggy or vulnerable libraries could be a huge headache\\n    and liability for downstream code and should be removed as quickly\\n    as possible.\\n2.  Some features may depend on broader adoption by the community. For\\n    instance, this approach would benefit greatly from python type\\n    hints, since the API could be constrained down to the expected\\n    types. Such type constraints would provide much more accuracy to the\\n    API version range as any changes could be detected. However, type\\n    hints may not be adopted in the python community at a high enough\\n    rate to truly be useful for this application.\\n3.  Source code is fundamentally flexible. There may be knots of code\\n    that even this approach could not cut through, especially as\\n    multiple languages and runtime module loading come into the picture.\\n    My personal hope would be that the code recognizes when these\\n    situations occur, provides its best guess of what is going on, and\\n    provides sufficient metadata to users so that they understand the\\n    decreased accuracy of the results. Fundamentally the tooling can\\n    only provide very educated guesses and context to users, who then\\n    need to go figure out what is actually going on inside the code.\\n\\n## Conclusion\\n\\nVersion number based pins are imprecise representations of API\\ncompatibility. More accurate representations based on source code\\ninspection would make the Conda-Forge ecosystem more robust and flexible\\nwhile reducing maintenance burden. Some of the path to achieving this is\\nbuilt, and near future steps can be achieved with current tooling and\\ndatabases."},{"id":"/2020/07/11/r-4","metadata":{"permalink":"/blog/2020/07/11/r-4","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-07-11-r-4.md","source":"@site/blog/2020-07-11-r-4.md","title":"R 4.0 Migration Retrospective","description":"While the R 4.0 migration has been functionally complete for quite a","date":"2020-07-11T00:00:00.000Z","formattedDate":"July 11, 2020","tags":[{"label":"scipy","permalink":"/blog/tags/scipy"}],"readingTime":5.15,"hasTruncateMarker":true,"authors":[{"name":"Christopher J. \'CJ\' Wright","title":"Member of conda-forge/core","url":"https://github.com/cj-wright","imageURL":"https://github.com/cj-wright.png","key":"cj-wright"},{"name":"Matthew R. Becker","title":"Member of conda-forge/core","url":"https://github.com/beckermr","imageURL":"https://github.com/beckermr.png","key":"beckermr"}],"frontMatter":{"authors":["cj-wright","beckermr"],"tags":["scipy"]},"unlisted":false,"prevItem":{"title":"The API Territory and Version Number Map","permalink":"/blog/2020/10/02/versions"},"nextItem":{"title":"Scipy 2020 Packaging BOF","permalink":"/blog/2020/07/06/scipy-bof"}},"content":"While the R 4.0 migration has been functionally complete for quite a\\nwhile, the recent migration of `r-java` and its dependents gives a good\\nopportunity to write a retrospective on the technical issues with\\nlarge-scale migrations in `conda-forge` and how we solved them.\\n\\n\x3c!--truncate--\x3e\\n\\nThe R 4.0 migration rebuilt every package in `conda-forge` that had\\n`r-base` as a requirement, including more than 2200 feedstocks. A\\nmigration of this size in `conda-forge` faces several hurdles. First,\\nsince every feedstock is a separate GitHub repository, one needs to\\nmerge more 2200 pull requests (PRs). Second, `conda-forge`\'s packages\\non `anaconda.org` are behind a CDN (content delivery network). This\\nservice reduces web hosting costs for Anaconda Inc. but introduces an\\napproximately 30 minute delay from when a package is uploaded to\\n`anaconda.org` and when it will appear as available using `conda` from\\nthe command line. Thus, even if the dependencies of a package have been\\nbuilt, we have to wait until they appear on the CDN before we can\\nsuccessfully issue the next PR and have it build correctly. Finally, the\\nexisting bot and `conda` infrastructure limited the throughput of the\\nmigrations, due in part to the speed of the `conda` solver.\\n\\nGiven the size of the R 4.0 migration, we took this opportunity to try\\nout a bunch of new technology to speed up large-scale migrations. The\\nmain enhancements were using GitHub Actions to automerge PRs, using\\n`mamba` to quickly check for solvability of package environments, and\\nenabling long-running migration jobs for the autotick bot. All told, the\\nbulk of the feedstocks for R 4.0 were rebuilt in less than a week, with\\nmany PRs being merged in 30 minutes or less from when they were issued.\\nThese enhancements to the autotick bot and `conda-forge` infrastructure\\ncan be used to enhance future migrations (e.g., Python 3.9) and reduce\\nmaintenance burdens for feedstocks.\\n\\n## Automerging conda-forge PRs\\n\\nIn a typical migration on `conda-forge`, we issue a PR to a feedstock\\nand then ask the feedstock maintainers to make sure it passes and merge\\nit. In the case of the R 4.0 migration, the maintainers of R packages on\\n`conda-forge` use a maintenance team (i.e., `@conda-forge/r`) on the\\nvast majority of feedstocks. This team is small and so merging over 2000\\nPRs by hand is a big undertaking. Thus, with their permission, we added\\nthe `conda-forge` automerge functionality to all R feedstocks that they\\nmaintain. The automerge bot, which relies on GitHub Actions, is able to\\nautomatically merge any PR from the autotick bot that passes the recipe\\nlinter, the continuous integration services, and has the special\\n`[bot automerge]` slug in the PR title. This feature removed the\\nbottleneck of waiting for maintainers to merge PRs and reduced the\\nmaintenance burden on the R maintenance team.\\n\\n## Checking Solvability with mamba\\n\\nWhile being able to automatically merge PRs removed much of the work of\\nperforming the R 4.0 migration, it relied on the PR building correctly\\nthe first time it was issued. Due to the CDN delays and the build times\\nof a package\'s dependencies, the dependencies of a package may not be\\nimmediately available after all of their migration PRs are merged. If\\nthe bot issued the packages migration PR before the dependents are\\navailable, the PR would fail with an unsolvable environment and have to\\nbe restarted manually. This failure would negate any of the benefits of\\nusing automerge in the first place.\\n\\nTo control for this edge case, we employed the `mamba` package to check\\nfor the solvability of a PR\'s environments before the PR was issued.\\n`mamba` is a fast alternative to `conda` that produces solutions for\\nenvironments orders of magnitude more quickly. Since, we have to perform\\nour checks of PR environments many times, an extremely fast solver was\\nessential for making the code efficient enough to run as part of the\\nautotick bot. We ended up using mamba to try to install the dependencies\\nfor every variant produced by the feedstock to be migrated. With this\\ncheck in place, the autotick bot was able to issue migration PRs that\\npassed on the first try and were thus automatically merged, many within\\n30 minutes or less.\\n\\n## Improving the Autotick Bot\'s Efficiency\\n\\nFinally, we made several upgrades to the autotick bot infrastructure to\\nincrease the uptime of the bot and its efficiency. First, we moved from\\nan hourly cron job to a set of chained CI jobs. This change eliminated\\ndowntime between the runs of the bot. Second, we started to refactor the\\nautotick bot from one monolithic piece of code into a distributed set of\\nmicroservices which perform various independent tasks in parallel. These\\nindependent tasks, used for things like checking the statuses of\\npreviously issued PRs, are run separately allowing the bot to spend more\\ntime issuing PRs. Finally, we optimized the internal prioritization of\\nthe PRs to make sure the bot was spending more time on larger migrations\\nwhere there is more work to do. More work on the autotick bot\\ninfrastructure, including work done by Vinicius Cerutti as part of the\\nGoogle Summer of Code program, will further streamline the bot\'s\\noperation.\\n\\nDespite some initial hiccups with the bot infrastructure, the migration\\nran quite smoothly for an endeavor of its size. The vast majority of\\nmigration PRs were completed within a week from when we started, which\\nis a first for a migration of this size on `conda-forge`. The largest\\nissue was solved recently, with the fixing of the `openjdk` recipe and\\nthe removal of `aarch64` and `ppc64le` builds from `r-java`, enabling\\nthe last large piece of the R ecosystem to be updated.\\n\\nLooking forward, the improvements we made for the R 4.0 migration seem\\nbroadly applicable to other migration tasks, including the yearly python\\nminor version bump. These kinds of large-scale migrations are\\nparticularly suitable, since they usually involve few changes to the\\nfeedstock itself and usually fail on CI when a broken package would be\\nproduced. Faster migrations will help to provide the latest features to\\ndownstream users and keep transition times to a minimum, helping to\\nfoster greater stability of the ecosystem and the seamless experience\\nusers have come to expect from `conda-forge`."},{"id":"/2020/07/06/scipy-bof","metadata":{"permalink":"/blog/2020/07/06/scipy-bof","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-07-06-scipy-bof.md","source":"@site/blog/2020-07-06-scipy-bof.md","title":"Scipy 2020 Packaging BOF","description":"Abstract:","date":"2020-07-06T00:00:00.000Z","formattedDate":"July 6, 2020","tags":[{"label":"scipy","permalink":"/blog/tags/scipy"}],"readingTime":0.83,"hasTruncateMarker":true,"authors":[{"name":"Christopher J. \'CJ\' Wright","title":"Member of conda-forge/core","url":"https://github.com/cj-wright","imageURL":"https://github.com/cj-wright.png","key":"cj-wright"}],"frontMatter":{"authors":["cj-wright"],"tags":["scipy"]},"unlisted":false,"prevItem":{"title":"R 4.0 Migration Retrospective","permalink":"/blog/2020/07/11/r-4"},"nextItem":{"title":"Conda-Forge Operational Risk","permalink":"/blog/2020/07/02/op-risk"}},"content":"## Abstract:\\n\\nHave some thoughts about conda-forge and how it can be expanded in a way\\nthat is sustainable? Join us in this virtual Birds of a Feather\\ndiscussion where we\'ll discuss maintenance, pain points, opportunities\\nwithin conda-forge. Any and all are welcome, and we especially are\\nseeking new viewpoints and opinions!\\n\\n\x3c!--truncate--\x3e\\n\\n## BOF questions:\\n\\n### State of Packaging\\n\\n- What is the state of conda-forge today?\\n- What improvements are in the works?\\n\\n### New features/ideas\\n\\n- What is something that\'s not in the works that you\'d like to see\\n  updated/improved?\\n- What are ways that folks who are interested but new to the community\\n  can get involved?\\n\\n### Maintenance\\n\\n- What is the maintenance burden and what pain points does it create?\\n- What are strategies to mitigate this burden?\\n\\n### Questions to the audience\\n\\n- What are your pain points when engaging with conda forge?\\n- What is something new you\'d like to see happen?\\n- What feedback do audience members have?"},{"id":"/2020/07/02/op-risk","metadata":{"permalink":"/blog/2020/07/02/op-risk","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-07-02-op-risk.md","source":"@site/blog/2020-07-02-op-risk.md","title":"Conda-Forge Operational Risk","description":"Recently I\'ve been thinking about operational risk (op. risk).","date":"2020-07-02T00:00:00.000Z","formattedDate":"July 2, 2020","tags":[{"label":"conda-forge","permalink":"/blog/tags/conda-forge"}],"readingTime":4.29,"hasTruncateMarker":true,"authors":[{"name":"Christopher J. \'CJ\' Wright","title":"Member of conda-forge/core","url":"https://github.com/cj-wright","imageURL":"https://github.com/cj-wright.png","key":"cj-wright"}],"frontMatter":{"authors":["cj-wright"],"tags":["conda-forge"]},"unlisted":false,"prevItem":{"title":"Scipy 2020 Packaging BOF","permalink":"/blog/2020/07/06/scipy-bof"},"nextItem":{"title":"PyPy builds on conda-forge","permalink":"/blog/2020/03/10/pypy"}},"content":"Recently I\'ve been thinking about operational risk (op. risk).\\nOperational risks arise from failures of processes, for instance a\\nmissing email, or an automated software system not running properly.\\nMany commercial institutions are interested in minimizing op. risk,\\nsince it is risk that produces no value, as opposed to risks associated\\nwith investing. This is also something I think about in my job at\\n[Lab49](https://www.lab49.com/), where I\'m a software engineering\\nconsultant focusing on financial institutions. I think there is also a\\ngood analogy for Conda-Forge, even though we are not a commercial\\noutfit. In this case the risk we incur isn\'t the potential for lost\\nearnings but frustration for our users and maintainers in the form of\\nbugs and lackluster user experience. In this post I explore three main\\nsources of operational risk for Conda-Forge: Automation, Top-Down\\nControl, and Self-Service Structure.\\n\\n\x3c!--truncate--\x3e\\n\\n## A brief conda-forge primer\\n\\nConda-Forge is an ecosystem and community that grew around building\\npackages for the conda package manager. Conda-Forge uses continuous\\nintegration services to build packages from GitHub repos called\\nfeedstocks. This structure enables teams of contributors to maintain\\npackages via a pull request based workflow. At time of writing\\nConda-Forge has over 10000 feedstocks and ships more than 120 million\\npackages a month.\\n\\n## Self-Service Structure\\n\\nConda-Forge is built around a self-service structure for each stage in a\\nfeedstock\'s lifecyle. The creation of new feedstocks relies on would be\\nmaintainers to submit PRs to staged-recipes. Although language specific\\nhelp teams and staged-recipes reviewers provide some assistance and\\noversight, the PR submitter plays the most important role in proposing\\nthe package and shepherding it to acceptance. Once the feedstock is\\naccepted the maintenance is federated with most upkeep being performed\\nby the maintainers, who have extensive permissions and control over the\\nfeedstock. If fixes or updates are needed for a package, maintainers and\\nusers are encouraged to open their own pull requests.\\n\\nThis structure can present a few challenges for minimizing op. risk. The\\nmost important challenge is the disconnect between feedstock maintainers\\nand users. While most maintainers are package users, most of our users\\nare not maintainers, and are unlikely to become maintainers. The\\ndisparity between maintainers and users can come from a few sources,\\nsome under our control and others not. For instance we can write better\\ndocumentation, lowering the barrier to entry, but we don\'t have control\\nover how our user\'s incentive structures value Conda-Forge\\ncontributions. This produces a gap in representation in the Conda-Forge\\norganizational structure, where non-maintainer users\' issues and\\ndesires are not communicated to maintainers and Core.\\n\\nFor instance, are we servicing the needs of developers using our\\nbinaries as dependencies to code they are compiling locally. As another\\nexample, are there support gaps for developers and scientists using\\nConda-Forge in academic and government laboratories, who might not have\\nthe skills or capacity to fix feedstocks. Our reliance on the public\\nGitHub platform may prevent some users without access from raising their\\nconcerns. Since these users may be under-represented we don\'t even know\\nif we are meeting their needs and how best to help.\\n\\n## Top-Down Control\\n\\nWhile the majority of Conda-Forge\'s permissions structure is federated,\\ncertain important parts are centralized, with the Core developers making\\nkey decisions. Often these decisions are focused on stability of the\\necosystem, for instance what versions of languages to support.\\nAdditionally, maintenance and enhancements to the Conda-Forge\\ninfrastructure are mostly performed by Core developers.\\n\\nHowever, the Core developers are usually experienced feedstock\\nmaintainers, expert conda users, and have bought into the Conda-Forge\\necosystem and mission. This means that decisions can be made without the\\nperspective of new users or maintainers, or from potential users that\\nare skeptical of the Conda-Forge approach.\\n\\nFor instance, decisions about application binary interface pins are\\nusually made by core, although these changes have impacts on downstream\\nmaintainers. It is possible that most maintainers don\'t know about what\\nthese pins are, how they are changed and how that affects their\\nfeedstocks.\\n\\n## Automation\\n\\nAutomation has been used to great effect to make Conda-Forge possible.\\nThe various bots and web services enable Conda-Forge\'s current scale,\\nproviding help and support from running builds, bumping versions, and\\nchecking feedstock quality. However, this automation presents its own\\noperational risks and magnifies existing operational risks.\\n\\nAutomation has a tendency to fail when we least expect it and often we\\nlack the ability to fix it. The January 2018 Travis-CI outage is a great\\nexample of this, where the CI service we were using for macOS builds\\nexperienced reduced capacity and then a complete outage, causing builds\\nto queue for days. Recently there was a sudden decrease in the number of\\nparallel builds on Azure causing a similar queue of builds. Automation\\ncan cause issues by enabling users to make decisions without all the\\nneeded information. While many feedstocks have effective smoke tests for\\ntheir packages the autotick bot doesn\'t currently check for new\\ndependencies, potentially leading to missing or incorrect package\\nmetadata.\\n\\n## Conclusion\\n\\nOverall Conda-Forge has managed its operational risk well. Most\\nimportantly Conda-Forge\'s transparent open source nature allows us to\\naddress these issues head on by engaging with the community."},{"id":"/2020/03/10/pypy","metadata":{"permalink":"/blog/2020/03/10/pypy","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-03-10-pypy.md","source":"@site/blog/2020-03-10-pypy.md","title":"PyPy builds on conda-forge","description":"conda-forge now supports PyPy3.6 as the python interpreter in a conda","date":"2020-03-10T00:00:00.000Z","formattedDate":"March 10, 2020","tags":[{"label":"infrastructure","permalink":"/blog/tags/infrastructure"}],"readingTime":2.335,"hasTruncateMarker":true,"authors":[{"name":"Isuru Fernando","title":"Member of conda-forge/core","url":"https://github.com/isuruf","imageURL":"https://github.com/isuruf.png","key":"isuruf"}],"frontMatter":{"authors":["isuruf"],"tags":["infrastructure"]},"unlisted":false,"prevItem":{"title":"Conda-Forge Operational Risk","permalink":"/blog/2020/07/02/op-risk"},"nextItem":{"title":"By the power of Grayskull... I have the Conda recipe!","permalink":"/blog/2020/03/05/grayskull"}},"content":"conda-forge now supports PyPy3.6 as the python interpreter in a conda\\nenvironment\\n\\nSupported platforms are,\\n\\n> - Linux-x86_64 (glibc 2.12 or newer)\\n> - OSX-x86_64 (OSX 10.9 or newer)\\n> - Linux-aarch64 (glibc 2.17 or newer)\\n> - Linux-ppc64le (glibc 2.17 or newer)\\n\\n\x3c!--truncate--\x3e\\n\\n## How to use PyPy\\n\\nTo use the PyPy builds you can do the following,\\n\\n```bash\\nconda config --set channel_priority strict\\nconda create -n pypy pypy\\nconda activate pypy\\n```\\n\\nIf you don\'t have a conda installation already, you can use\\n[miniforge-pypy3](https://github.com/conda-forge/miniforge#miniforge-pypy3)\\nwhich gives you a conda installation powered by pypy itself.\\n\\nHowever as of the writing of this post, not many conda packages can be\\ninstalled into this environment, but noarch packages which do not depend\\non the python version nor the interpreter can be installed. For eg,\\nmpmath is a noarch package without any dependencies.\\n\\n```bash\\nconda install mpmath    # succeeds\\nconda install numpy     # fails as of March 10, 2020\\n```\\n\\n**UPDATE**: numpy and scipy builds are working as of April 10, 2020.\\n\\nAll python C extensions needs to be rebuilt for the PyPy ABI. This is\\ncurrently on the way and can be tracked at the [status\\npage](https://conda-forge.org/status).\\n\\n## python_abi Package\\n\\nAs part of adding support for PyPy and to keep the older python builds\\nworking, a python_abi package was added. This defines the abi for the\\npython package and any non-noarch python packages will have a dependency\\non this package. Older python downstream packages like numpy had their\\nmetadata patched to add a CPython ABI. You can ask for a specific python\\nABI.\\n\\n```bash\\nconda install \\"python_abi=*=*_cp27mu\\"\\n```\\n\\nIf you are using python packages from packages other than defaults, you\\nwill be able to install python extensions built with CPython ABI into\\nPyPy builds as their metadata have not been patched. Solution in this\\ncase is to hotfix the metadata which is available to only high volume\\nconda channel or to rebuild those packages with the new python packages\\nand mark the older ones as broken.\\n\\nUsing the newer packages will rerender the following requirement to add\\na dependency on python_abi. For eg,\\n\\n```yaml\\nrequirements:\\n  host:\\n    - python 3.6\\n  run:\\n    - python\\n```\\n\\nis rendered as,\\n\\n```yaml\\nrequirements:\\n  host:\\n    - python 3.6.10 h9d8adfe_1009_cpython\\n  run:\\n    - python >=3.6,<3.7.0a0\\n    - python_abi 3.6 *_cp36m\\n```\\n\\nwhereas,\\n\\n```yaml\\nrequirements:\\n  host:\\n    - python 3.6 *_73_pypy\\n  run:\\n    - python\\n```\\n\\nis rendered as,\\n\\n```yaml\\nrequirements:\\n  host:\\n    - python 3.6.9 0_73_pypy\\n  run:\\n    - python >=3.6,<3.7.0a0\\n    - python_abi 3.6 *_pypy36_pp73\\n```\\n\\nNote that the PyPy ABI tag has `pp73` at the end which\\nindicates that the ABI is stable only for PyPy3.6 7.3.x series.\\n\\nThis opens up the possibility of adding debug builds of python and\\nbuilding extension packages using the Python Debug ABI.\\n\\nDiscussion on the PyPy builds can be found in the issue\\n[conda-forge/conda-forge.github.io#867](https://github.com/conda-forge/conda-forge.github.io/issues/867)."},{"id":"/2020/03/05/grayskull","metadata":{"permalink":"/blog/2020/03/05/grayskull","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-03-05-grayskull.md","source":"@site/blog/2020-03-05-grayskull.md","title":"By the power of Grayskull... I have the Conda recipe!","description":"The main goal of the Skeleto~~n~~r is to conquer Grayskull.","date":"2020-03-05T00:00:00.000Z","formattedDate":"March 5, 2020","tags":[{"label":"conda","permalink":"/blog/tags/conda"}],"readingTime":6.925,"hasTruncateMarker":true,"authors":[{"name":"Marcelo Duarte Trevisani","title":"Member of conda-forge/core","url":"https://github.com/marcelotrevisani","imageURL":"https://github.com/marcelotrevisani.png","key":"marcelotrevisani"}],"frontMatter":{"authors":["marcelotrevisani"],"tags":["conda"]},"unlisted":false,"prevItem":{"title":"PyPy builds on conda-forge","permalink":"/blog/2020/03/10/pypy"},"nextItem":{"title":"Google Summer of Code 2020 improved automatic maintenance of conda-forge","permalink":"/blog/2020/02/04/gsoc"}},"content":"_The main goal of the Skeleto_~~n~~_r is to conquer Grayskull._\\n\\n## Introduction\\n\\nAll jokes aside, the new project\\n[grayskull](https://github.com/marcelotrevisani/grayskull) was created\\nwith the **intention** of generating better Conda recipes that would\\nallow to package properly projects available in different channels such\\nas PyPI, CRAN, Conan, GitHub register, GitHub repositories and so on. On\\ntop of that, Grayskull is also being developed to help\\n[conda-forge](https://conda-forge.org/) to update recipes.\\n\\n\x3c!--truncate--\x3e\\n\\n## Current status\\n\\nCurrently, Grayskull (version `0.2.1`) is able to generate recipes just\\nlooking for packages on [PyPI](https://pypi.org/), and it is available\\non [PyPI](https://pypi.org/project/grayskull/) and\\n[conda-forge](https://github.com/conda-forge/grayskull-feedstock). The\\nGitHub repository for this package is:\\n[marcelotrevisani/grayskull](https://github.com/marcelotrevisani/grayskull).\\n\\nBefore Grayskull, we just had `conda-build skeleton` to generate recipes\\nfor Python packages on PyPI. In all other aspects, the difference of\\nquality of the generated recipes, and also the time spent to generate\\nthem have a big discrepancy when compared to `conda-build skeleton` and\\n`grayskull`. Grayskull generates recipes taking in consideration the\\nplatform, Python version available, selectors, compilers (Fortran, C and\\nC++), packages constrains, license type, license file, and so forth. It\\nuses metadata available from multiple sources to try to create the best\\nrecipe possible.\\n\\n## Installation\\n\\nYou can install `grayskull` using `pip` or `conda`. `Grayskull` does not\\nrely on `conda` to run and can generate recipes with minimum\\ndependencies.\\n\\n### With conda\\n\\nGrayskull is available on the conda-forge channel.\\n\\n```bash\\nconda install -c conda-forge grayskull\\n```\\n\\n### With pip\\n\\n```bash\\npip install grayskull\\n```\\n\\n## Grayskull vs conda-build skeleton\\n\\nThere are some differences of recipes generated by `grayskull` and\\n`conda skeleton`. Taking as example the `pytest` recipe, which has\\nselectors for platforms, Python version constrains, and has several\\npackage constrains as well.\\n\\n### Grayskull (0.2.1) - took 4 seconds to generate the recipe\\n\\n```yaml\\n{% set name = \\"pytest\\" %}\\n{% set version = \\"5.3.5\\" %}\\n\\npackage:\\n  name: {{ name|lower }}\\n  version: {{ version }}\\n\\nsource:\\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\\n  sha256: 0d5fe9189a148acc3c3eb2ac8e1ac0742cb7618c084f3d228baaec0c254b318d\\n\\nbuild:\\n  number: 0\\n  skip: true   # [py2k]\\n  entry_points:\\n    - pytest=pytest:main\\n    - py.test=pytest:main\\n  script: {{ PYTHON }} -m pip install . -vv\\n\\nrequirements:\\n  host:\\n    - pip\\n    - python\\n    - setuptools >=40.0\\n    - setuptools_scm\\n  run:\\n    - atomicwrites >=1.0      # [win]\\n    - attrs >=17.4.0\\n    - colorama      # [win]\\n    - importlib-metadata >=0.12        # [py<38]\\n    - more-itertools >=4.0.0\\n    - packaging\\n    - pathlib2 >=2.2.0        # [py<36]\\n    - pluggy <1.0,>=0.12\\n    - py >=1.5.0\\n    - python\\n    - wcwidth\\n\\ntest:\\n  imports:\\n    - pytest\\n  commands:\\n    - pip check\\n    - pytest --help\\n    - py.test --help\\n  requires:\\n    - pip\\n\\nabout:\\n  home: https://pypi.org/project/pytest/\\n  summary: \'pytest: simple powerful testing with Python\'\\n  dev_url: https://github.com/pytest-dev/pytest\\n  license: MIT\\n  license_file: LICENSE\\n\\nextra:\\n  recipe-maintainers:\\n    - marcelotrevisani\\n```\\n\\n### Skeleton (3.18.11) - took 31 seconds to generate the recipe\\n\\n```yaml\\n{% set name = \\"pytest\\" %}\\n{% set version = \\"5.3.5\\" %}\\n\\npackage:\\n  name: \\"{{ name|lower }}\\"\\n  version: \\"{{ version }}\\"\\n\\nsource:\\n  url: \\"https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\\"\\n  sha256: 0d5fe9189a148acc3c3eb2ac8e1ac0742cb7618c084f3d228baaec0c254b318d\\n\\nbuild:\\n  number: 0\\n  script: \\"{{ PYTHON }} -m pip install . -vv\\"\\n\\nrequirements:\\n  host:\\n    - atomicwrites >=1.0\\n    - attrs >=17.4.0\\n    - colorama;sys_platform ==\\"win32\\"\\n    - importlib-metadata >=0.12\\n    - more-itertools >=4.0.0\\n    - packaging\\n    - pathlib2 >=2.2.0\\n    - pip\\n    - pluggy >=0.12,<1.0\\n    - py >=1.5.0\\n    - python\\n    - wcwidth\\n  run:\\n    - atomicwrites >=1.0\\n    - attrs >=17.4.0\\n    - colorama;sys_platform ==\\"win32\\"\\n    - importlib-metadata >=0.12\\n    - more-itertools >=4.0.0\\n    - packaging\\n    - pathlib2 >=2.2.0\\n    - pluggy >=0.12,<1.0\\n    - py >=1.5.0\\n    - python\\n    - wcwidth\\n\\nabout:\\n  home: The package home page\\n  license: MIT\\n  license_family: MIT\\n  license_file:\\n  summary: \\"pytest: simple powerful testing with Python\\"\\n  doc_url:\\n  dev_url:\\n\\nextra:\\n  recipe-maintainers:\\n    - your-github-id-here\\n```\\n\\n### Original recipe on `conda-forge` for `pytest 5.3.5`\\n\\n```yaml\\n{% set version = \\"5.3.5\\" %}\\n\\npackage:\\n  name: pytest\\n  version: {{ version }}\\n\\nsource:\\n  url: https://pypi.io/packages/source/p/pytest/pytest-{{ version }}.tar.gz\\n  sha256: 0d5fe9189a148acc3c3eb2ac8e1ac0742cb7618c084f3d228baaec0c254b318d\\n\\nbuild:\\n  skip: True  # [py27]\\n  number: 1\\n  script: \\"{{ PYTHON }} setup.py install --single-version-externally-managed --record record.txt\\"\\n  entry_points:\\n    - py.test = py.test:main\\n    - pytest = py.test:main\\n\\nrequirements:\\n  host:\\n    - pip\\n    - python\\n    - setuptools >=40.0\\n    - setuptools_scm\\n  run:\\n    - atomicwrites >=1.0  # [win]\\n    - attrs >=17.4.0\\n    - colorama  # [win]\\n    - importlib_metadata >=0.12  # [py<38]\\n    - more-itertools >=4.0\\n    - packaging\\n    - pathlib2 >=2.2.0  # [py<36]\\n    - pluggy >=0.12,<1.0\\n    - py >=1.5.0\\n    - python\\n    - setuptools >=40.0\\n    - wcwidth\\n  run_constrained:\\n    # pytest-faulthandler 2 is a dummy package.\\n    # if an older version of fault-handler is installed, it will conflict with pytest >=5.\\n    - pytest-faulthandler >=2\\n\\ntest:\\n  commands:\\n    - pytest -h\\n  imports:\\n    - pytest\\n\\nabout:\\n  home: https://docs.pytest.org/en/latest/\\n  license: MIT\\n  license_file: LICENSE\\n  summary: \'Simple and powerful testing with Python.\'\\n  description: |\\n    The pytest framework makes it easy to write small tests, yet scales to\\n    support complex functional testing for applications and libraries.\\n    doc_url: https://docs.pytest.org/en/latest/\\n    dev_url: https://github.com/pytest-dev/pytest/\\n\\nextra:\\n  recipe-maintainers:\\n    - flub\\n    - goanpeca\\n    - nicoddemus\\n    - ocefpaf\\n    - mingwandroid\\n```\\n\\n### Major differences\\n\\n| Attribute             | Grayskull (0.2.1)                                                                                            | Skeleton (3.18.11)                                                                                                                                                                                                               |\\n| --------------------- | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| **Command**           | \u2705 grayskull pypi pytest                                                                                     | \u2705 conda skeleton pypi pytest                                                                                                                                                                                                    |\\n| **Time**              | \u2705 4 seconds                                                                                                 | \u274c 31 seconds                                                                                                                                                                                                                    |\\n| **License**           | \u2705 Added the license file and license type correctly                                                         | \u2757\ufe0f Added just the license type                                                                                                                                                                                                  |\\n| **Host Requirements** | \u2705 Added correctly all the host requirements                                                                 | \u274c it didn\'t add the correctly the host dependencies. It added unnecessary dependencies and it is missing quite a few of them necessary to build the package                                                                     |\\n| **Run Requirements**  | \u2705 Missing just setuptools from the host requirements (but this dependency is not defined on pytest package) | \u274c incorrect dependencies added to the project                                                                                                                                                                                   |\\n| **Selectors**         | \u2705 Skipping correctly Python 2 and added selectors for windows and python versions                           | \u274c it didn\'t add any information regarding selectors. Actually conda-build added wrong information which will result in a broken recipe. For example \'sys_platform == win32\' was added which is a wrong format for conda recipes |\\n| **Entry points**      | \u2705 Added all entry points correctly                                                                          | \u274c No entry points                                                                                                                                                                                                               |\\n| **Does it build?**    | \u2705 YES                                                                                                       | \u274c NO                                                                                                                                                                                                                            |\\n\\nIn the case of `noarch: python`, Grayskull is smart enough to detect\\nwhen the recipe supports it, which is not done by Skeleton. It is\\nimportant to highlight that Skeleton does not detect compilers as well.\\nNevertheless, Grayskull always try to detect it.\\n\\n## Usage Grayskull (0.2.1)\\n\\nProject options:\\n\\n```bash\\n$ grayskull --help\\nusage: grayskull [-h] [--version] {pypi} ...\\n\\nGrayskull - Conda recipe generator\\n\\npositional arguments:\\n{pypi}         Options to generate PyPI recipes\\npypi         Generate recipes based on PyPI\\n\\noptional arguments:\\n-h, --help     show this help message and exit\\n--version, -v  Print Grayskull version and exit\\n```\\n\\n```bash\\n$ grayskull pypi --help\\nusage: grayskull pypi [-h] [--maintainers MAINTAINERS [MAINTAINERS...]]\\n[--output OUTPUT]\\npypi_packages [pypi_packages ...]\\n\\npositional arguments:\\npypi_packages         Specify the PyPI package name.\\n\\noptional arguments:\\n-h, --help            show this help message and exit\\n--maintainers MAINTAINERS [MAINTAINERS ...], -m MAINTAINERS [MAINTAINERS...] List of maintainers which will be added to the recipe.\\n--output OUTPUT, -o OUTPUT Path to where the recipe will be created\\n```\\n\\nTo generate the recipe you can just call `grayskull` and pass the\\nchannel (as for now we are just supporting PyPI, it should be pypi) and\\nthe package name. You should also specify an output folder using the\\noption `--output` or `-o` and it will create the package folder, and the\\nrecipe in there. It is important to note that the user can specify a\\nlist of maintainers which will be added to the recipe using the option\\n`--maintainers`.\\n\\nExample for pytest:\\n\\n![Grayskull CLI](https://raw.githubusercontent.com/marcelotrevisani/grayskull/15e4a0317da4e6c2f66a381329682b7e9dc70da0/docs/images/cli_example_grayskull.gif)\\n\\nIf you need to specify the package version you can do it just puting the\\nequal sign after the package name and the version just right after that.\\nExample:\\n\\n```bash\\ngrayskull pypi requests=2.21.0\\n```\\n\\nor\\n\\n```bash\\ngrayskull pypi requests==2.21.0\\n```\\n\\n![Grayskull pinned package -requests](https://raw.githubusercontent.com/marcelotrevisani/grayskull/15e4a0317da4e6c2f66a381329682b7e9dc70da0/docs/images/cli_example_grayskull_version.gif)\\n\\nIf you want to generate multiple recipes just pass a list of packages,\\nsuch as:\\n\\n```bash\\ngrayskul pypi pytest requests=2.21.0 colorama\\n```\\n\\n## Future plans\\n\\n> - For the next major version (1.0.0) it is planned to add the\\n>   functionality to be able to load the recipe and update just parts\\n>   of it;\\n> - Generate Conda recipes using CRAN (R) channel (2.0.0);\\n> - Generate Conda recipes using Conan (C++) channel (3.0.0);\\n\\n## Issues\\n\\nAny problem, question, suggestions please feel free to open [an issue on\\nthe repository](https://github.com/marcelotrevisani/grayskull/issues).\\n\\nContributions are very welcome! :)\\n\\n---\\n\\nThis work was possible thanks to the [NumFOCUS](https://numfocus.org/)\\nSmall Development Grant program."},{"id":"/2020/02/04/gsoc","metadata":{"permalink":"/blog/2020/02/04/gsoc","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2020-02-04-gsoc.md","source":"@site/blog/2020-02-04-gsoc.md","title":"Google Summer of Code 2020 improved automatic maintenance of conda-forge","description":"The conda-forge \\"autotick\\" bot is a crucial part of conda-forge\'s","date":"2020-02-04T00:00:00.000Z","formattedDate":"February 4, 2020","tags":[{"label":"autotick-bot","permalink":"/blog/tags/autotick-bot"},{"label":"gsoc","permalink":"/blog/tags/gsoc"}],"readingTime":2.98,"hasTruncateMarker":true,"authors":[{"name":"Filipe Pires Alvarenga Fernandes","title":"Member of conda-forge/core","url":"https://github.com/ocefpaf","imageURL":"https://github.com/ocefpaf.png","key":"ocefpaf"}],"frontMatter":{"authors":["ocefpaf"],"tags":["autotick-bot","gsoc"]},"unlisted":false,"prevItem":{"title":"By the power of Grayskull... I have the Conda recipe!","permalink":"/blog/2020/03/05/grayskull"},"nextItem":{"title":"Automatically Deployed ABI Migrations","permalink":"/blog/2019/12/06/cfep09"}},"content":"The `conda-forge` \\"autotick\\" bot is a crucial part of `conda-forge`\'s\\ninfrastructure. It enables automatic maintenance of `conda-forge`\\npackages by pushing version updates to the underlying software and\\nenabling large migrations of packages from one dependency to another\\n(e.g., Python 3.7 to Python 3.8). As `conda-forg` grows in size, with\\nover 9,000 packages to date, automatic maintenance of the `conda-forge`\\necosystem will become even more important.\\n\\n\x3c!--truncate--\x3e\\n\\nWe here at `conda-forge` have a large number of potential Google Sumer\\nof Code projects around maintenance and development of the autotick bot\\ninfrastructure. These projects are high-impact, affecting the entire\\n`conda-forge` ecosystem. They also cover multiple systems including\\ndatabases, `conda`\'s CDN provider, continuous integration providers,\\nand user interactions on GitHub.\\n\\nWant to be a part of the team? Great! Take a look at the projects below\\nand get in touch with us on GitHub! You can check the [GSoC\\nlabel](https://github.com/regro/cf-scripts/labels/GSOC) for a\\ndetailed listing of the issues that need work.\\n\\n1.  Maintenance and Refactoring\\n\\n    We have a large backlog of maintenance and refactoring issues that\\n    are great for people with a range of experience from beginners to\\n    true code ninjas.\\n\\n    - Integration Testing for the Autotick Bot\\n\\n      > Run true integration testing on a copy of the graph to better\\n      > test code changes and improve our CI process.\\n      >\\n      > **Issue**: [regro/cf-scripts261](https://github.com/regro/cf-scripts/issues/261)\\n      >\\n      > **Experience Level**: advanced\\n\\n    - Work on the \\"code hardening\\"\\n      [Milestone](https://github.com/regro/cf-scripts/milestone/4)\\n\\n      Address any of the issues in the milestone above related to code\\n      refactoring and cleanup.\\n\\n      **Issues**: [regro/cf-scripts milestone #4](https://github.com/regro/cf-scripts/milestone/4)\\n\\n      **Experience Level**: beginner to advanced\\n\\n2.  Automated PRs for Globally Pinned Packages\\n\\n    `conda-forge` maintains a list of globally pinned packages. These\\n    are typically dependencies whose version needs to be the same across\\n    all of `conda-forge` (e.g., the compiler versions or packages like\\n    `HDF5`). While we have infrastructure to run a migration of the\\n    downstream packages from a given pinned package, we do not have\\n    automated infrastructure to propose the migration of the pin itself.\\n    The project here is to add this functionality to our infrastructure.\\n\\n    **Issue**: [regro/cf-scripts#665](https://github.com/regro/cf-scripts/issues/665)\\n\\n    **Experience Level**: advanced\\n\\n3.  Check the `conda` CDN for Updated Packages before Issuing PRs in a\\n    Migration\\n\\n    `conda` relies on a CDN provider to serve the index of available\\n    packages. There is a moderate ~30 minute delay between when a\\n    package is uploaded to `anaconda.org` and when it will appear in the\\n    `conda` index. We currently do not take this delay into account when\\n    issuing PRs in a migration.\\n\\n    **Issue**: [regro/cf-scripts#595](https://github.com/regro/cf-scripts/issues/595)\\n\\n    **Experience Level**: beginner\\n\\n4.  Finish Migrations with PR into the `conda-forge` Pinnings File\\n\\n    Right now, when the migration of say package `ABC` to version `X`\\n    from version `Y` is done, we do not automatically merge the change\\n    in the globally pinned value of `ABC` into our listing of global\\n    pinnings. We should be issuing a PR to the pinnings file once we\\n    have determined that a suitable fraction of the packages effected by\\n    a migration have been properly rebuilt.\\n\\n    **Issue**: [regro/cf-scripts#595](https://github.com/regro/cf-scripts/issues/595)\\n\\n    **Experience Level**: moderate\\n\\n5.  Fully Render `conda` Packages in order to Determine Migration\\n    Dependencies\\n\\n    Determining the dependencies of a given package is actually a\\n    computation expensive task due to the way `conda` recipes are\\n    structured and parametrized through the use of `Jinja2` and\\n    `conda-build-config.yaml` files. Currently, the autotick bot\\n    examines the static metadata in the `meta.yaml` file and not the\\n    fully rendered metadata. For this reason, we sometimes miss\\n    dependencies of a given package that need to be migrated first.\\n    Addressing this issue involves both calling the rendering process\\n    and also scaling that process to the entire set of `conda-forge`\\n    packages.\\n\\n    **Issue**: [regro/cf-scripts#664](https://github.com/regro/cf-scripts/issues/664)\\n\\n    **Experience Level**: moderate"},{"id":"/2019/12/06/cfep09","metadata":{"permalink":"/blog/2019/12/06/cfep09","editUrl":"https://github.com/conda-forge/conda-forge.github.io/tree/main/blog/2019-12-06-cfep09.md","source":"@site/blog/2019-12-06-cfep09.md","title":"Automatically Deployed ABI Migrations","description":"Handling application binary interface (ABI) migrations has always been a","date":"2019-12-06T00:00:00.000Z","formattedDate":"December 6, 2019","tags":[{"label":"autotick-bot","permalink":"/blog/tags/autotick-bot"}],"readingTime":1.855,"hasTruncateMarker":true,"authors":[{"name":"Christopher J. \'CJ\' Wright","title":"Member of conda-forge/core","url":"https://github.com/cj-wright","imageURL":"https://github.com/cj-wright.png","key":"cj-wright"}],"frontMatter":{"authors":["cj-wright"],"tags":["autotick-bot"]},"unlisted":false,"prevItem":{"title":"Google Summer of Code 2020 improved automatic maintenance of conda-forge","permalink":"/blog/2020/02/04/gsoc"}},"content":"Handling application binary interface (ABI) migrations has always been a\\nhassle for Conda-Forge. Maintaining ABI consistency helps enable the\\n\\"just use conda-forge\\" experience for many of our users, making\\ncertain that numpy\'s blas is the same as scipy\'s. As libraries update\\ntheir code, the new versions may be ABI incompatible, as function\\nsignatures and other symbols may have changed, leading to the dreaded\\n`SegmentationFault` and other errors.\\n\\n\x3c!--truncate--\x3e\\n\\nConda-Forge handles this by having a pinning file that tracks all the\\ncurrently supported ABIs. These pinned ABIs are then used to build the\\ndownstream packages, making certain that all are consistent. As new\\nversions of pinned software are released the pins are updated, causing a\\nmigration of the pin, and the rebuilding of all packages which rely on\\nthe pinned package. In the past, this was handled by a change to the\\nglobal pinnings and a subsequent migration via the auto-tick bot. While\\nthis worked, there were issues that this created. Firstly, this approach\\ncould cause unsatisfiable build dependencies for new packages, as some\\nof the new package\'s dependencies had been compiled with the new pins,\\nbut not all. Secondly, migrations happened in series, if a second pin\\nwas moved while the first was being migrated then the migration could go\\nwrong as packages which were being rebuilt for the first pin got the\\nsecond pin before they were ready.\\n\\nConda-Forge Core has recently approved CFEP-9, a migration policy to fix\\nthese issues. With CFEP-9 pinnings are proposed as small yaml snippets\\nwhich contain the new pins. The auto-tick bot then starts migrating the\\npackages in order, applying the yaml snippet to each package in turn. If\\na second pinning change is issued then the bot starts the migration for\\nthat package too, enabling the two migrations to work independently. If\\na package needs a change in both pins then the maintainers can choose\\nthe order in which they apply the pins by merging one pin before the\\nother.\\n\\nThis approach will yield much greater stability in migrations and will\\nenable more maintainers to issue migrations. Migrations can be issued by\\nputting a PR into\\n[conda-forge/conda-forge-pinning-feedstock](https://github.com/conda-forge/conda-forge-pinning-feedstock),\\nadding a file to the `migrations` folder, PRs into the auto-tick bot are\\nnot needed anymore."}]}')}}]);